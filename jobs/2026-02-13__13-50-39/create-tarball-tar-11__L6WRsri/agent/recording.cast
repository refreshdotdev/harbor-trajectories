{"version": 2, "width": 160, "height": 40, "timestamp": 1771008651, "env": {"SHELL": "/bin/bash", "TERM": "screen"}}
[0.005521, "o", "\u001b[?2004hroot@deb58943-740c-4aba-bfc4-495080ea5672:~# "]
[1.015214, "i", "clear\r"]
[1.015351, "o", "clear\r\n\u001b[?2004l\r"]
[1.016173, "o", "\u001b[H\u001b[J"]
[1.016317, "o", "\u001b[?2004h"]
[1.016358, "o", "root@deb58943-740c-4aba-bfc4-495080ea5672:~# "]
[35.448634, "i", "cd /home/user\n"]
[35.448778, "o", "cd /home/user\r\n\u001b[?2004l\r"]
[35.448857, "o", "\u001b[?2004h"]
[35.44888, "o", "root@deb58943-740c-4aba-bfc4-495080ea5672:/home/user# "]
[35.555934, "i", "ls -la\n"]
[35.556059, "o", "ls -la\r\n\u001b[?2004l\r"]
[35.557286, "o", "total 0\r\n"]
[35.557329, "o", "drwxr-xr-x 1 root root 48 Feb 13 18:50 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root 26 Feb 13 18:50 \u001b[01;34m..\u001b[0m\r\ndrwxr-xr-x 1 root root  6 Feb 13 18:50 \u001b[01;34mbackups\u001b[0m\r\ndrwxr-xr-x 1 root root 28 Feb 13 18:50 \u001b[01;34mtickets\u001b[0m\r\n"]
[35.557552, "o", "\u001b[?2004h"]
[35.557582, "o", "root@deb58943-740c-4aba-bfc4-495080ea5672:/home/user# "]
[35.688976, "i", "cat > backup_tool.py << 'EOF'\n#!/usr/bin/env python3\n\"\"\"\nLegacy System Backup Tool\nCreates a gzip-compressed tarball of a directory with safety measures,\ngenerates a JSON manifest, and creates a legacy summary file.\n\"\"\"\nimport os\nimport sys\nimport tarfile\nimport json\nimport hashlib\nimport datetime\nimport glob\nimport io\nimport shutil\n\n# Configuration\nSOURCE_DIR = \"/home/user/tickets/issue_20230815/\"\nTAR_OUTPUT_PATH = \"/home/user/backups/support_issue_20230815_legacy.tar.gz\"\nMANIFEST_OUTPUT_PATH = \"/home/user/backups/backup_manifest.json\"\nSUMMARY_OUTPUT_PATH = \"/home/user/backups/backup_summary.txt\"\nIGNORE_FILENAME = \".backupignore\"\n\ndef read_ignore_file(directory):\n    \"\"\"Read and parse the .backupignore file.\"\"\"\n    ignore_patterns = []\n    ignore_file_path = os.path.join(directory, IGNORE_FILENAME)\n    try:\n        with open(ignore_file_path, 'r') as f:\n            for line in f:\n                line = line.strip()\n                if line and not line.startswith('#'):\n                    ignore_patterns.appe"]
[35.689014, "i", "nd(line)\n    except FileNotFoundError:\n        pass  # Ignore file not present\n    return ignore_patterns\n\ndef should_ignore_file(path, ignore_patterns):\n    \"\"\"Check if a file should be ignored based on patterns.\"\"\"\n    for pattern in ignore_patterns:\n        if glob.fnmatch.fnmatch(path, pattern):\n            return True\n    return False\n\ndef archive_directory(source_dir, tar_path, ignore_patterns):\n    \"\"\"Create a tarball with dereferenced symlinks, skipping broken and recursive symlinks.\"\"\"\n    try:\n        with tarfile.open(tar_path, \"w:gz\") as tar:\n            for root, dirs, files in os.walk(source_dir):\n                # Filter directories based on ignore patterns\n                dirs[:] = [d for d in dirs if not should_ignore_file(os.path.join(root, d), ignore_patterns)]\n                \n                for file in files:\n                    full_path = os.path.join(root, file)\n                    \n                    # Check if file should be ignored\n                    if should_ignore_file(full_pa"]
[35.689159, "i", "th, ignore_patterns):\n                        continue\n                    \n                    # Check for broken symlinks\n                    if os.path.islink(full_path):\n                        if not os.path.exists(full_path):\n                            print(f\"Skipping broken symlink: {full_path}\")\n                            continue\n                        # Dereference symlink for inclusion\n                        file_path = os.path.realpath(full_path)\n                    else:\n                        file_path = full_path\n                    \n                    # Add file to archive (dereferenced)\n                    arcname = os.path.relpath(file_path, start=os.path.dirname(source_dir))\n                    tar.add(file_path, arcname=arcname, recursive=False)\n    except Exception as e:\n        print(f\"Error creating archive: {e}\")\n        sys.exit(1)\n\n\ndef generate_manifest(tar_path, manifest_path):\n    \"\"\"Generate a JSON manifest with archive metadata.\"\"\"\n    try:\n        file_size = os.path.get"]
[35.689176, "o", "cat > backup_tool.py << 'EOF'\r\n\u001b[?2004l\rth, ignore_patterns):\r\n                        continue\r\n                    \r\n                    # Check for broken symlinks\r\n                    if os.path.islink(full_path):\r\n                        if not os.path.exists(full_path):\r\n          "]
[35.689224, "i", "size(tar_path)\n        \n        md5_hash = hashlib.md5()\n        sha256_hash = hashlib.sha256()\n        \n        with open(tar_path, 'rb') as f:\n            while True:\n                data = f.read(8192)\n                if not data:\n                    break\n                md5_hash.update(data)\n                sha256_hash.update(data)\n        \n        manifest_data = {\n            \"archive_name\": os.path.basename(tar_path),\n            \"file_size_bytes\": file_size,\n            \"md5_hash\": md5_hash.hexdigest(),\n            \"sha256_hash\": sha256_hash.hexdigest(),\n            \"created_at_utc\": datetime.datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')\n        }\n        \n        with open(manifest_path, 'w') as f:\n            json.dump(manifest_data, f, indent=2)\n        \n        return manifest_data\n    except Exception as e:\n        print(f\"Error generating manifest: {e}\")\n        sys.exit(1)\n\n\ndef generate_legacy_summary(summary_path, manifest_sha256):\n    \"\"\"Generate the legacy summary file with ISO-8859-1 e"]
[35.68925, "o", "                  print(f\"Skipping broken symlink: {full_path}\")\r\n                            continue\r\n                        # Dereference symlink for inclusion\r\n                        file_path = os.path.realpath(full_path)\r\n                    else:\r\n                        file_path = full_path\r\n                    \r\n                    # Add file to archive (dereferenced)\r\n                    arcname ="]
[35.689278, "i", "ncoding and CRLF line endings.\"\"\"\n    try:\n        # Use latin-1 encoding and add CRLF line endings\n        content = \"Legacy Backup Operation © 2023\\r\\nManifest SHA256: {hash}\\r\\n\".format(hash=manifest_sha256)\n        \n        with open(summary_path, 'wb') as f:\n            f.write(content.encode('latin-1'))\n    except Exception as e:\n        print(f\"Error generating legacy summary: {e}\")\n        sys.exit(1)\n\n\ndef main():\n    print(\"Starting legacy backup process...\")\n    \n    # Create backups directory if it doesn't exist\n    backups_dir = os.path.dirname(TAR_OUTPUT_PATH)\n    if not os.path.exists(backups_dir):\n        os.makedirs(backups_dir)\n        print(f\"Created directory: {backups_dir}\")\n    \n    # Check if source directory exists\n    if not os.path.isdir(SOURCE_DIR):\n        print(f\"Error: Source directory not found: {SOURCE_DIR}\")\n        sys.exit(1)\n    \n    # Read ignore file patterns\n    ignore_patterns = read_ignore_file(SOURCE_DIR)\n    print(f\"Loaded {len(ignore_patterns)} ignore patterns from"]
[35.689294, "o", " os.path.relpath(file_path, start=os.path.dirname(source_dir))\r\n                    tar.add(file_path, arcname=arcname, recursive=False)\r\n    except Exception as e:\r\n        print(f\"Error creating archive: {e}\")\r\n        sys.exit(1)\r\n\r\n\r\ndef generate_manifest(tar_path, manifest_path):\r\n    \"\"\"Generate a JSON manifest with archive metadata.\"\"\"\r\n    try:\r\n        file_size = os.path.get"]
[35.689337, "i", " {os.path.join(SOURCE_DIR, IGNORE_FILENAME)}\")\n    \n    # Create the archive\n    print(f\"Creating archive: {TAR_OUTPUT_PATH}\")\n    archive_directory(SOURCE_DIR, TAR_OUTPUT_PATH, ignore_patterns)\n    \n    # Generate manifest\n    manifest_data = generate_manifest(TAR_OUTPUT_PATH, MANIFEST_OUTPUT_PATH)\n    print(f\"Generated manifest: {MANIFEST_OUTPUT_PATH}\")\n    print(f\"Manifest SHA256: {manifest_data['sha256_hash']}\")\n    \n    # Generate legacy summary\n    generate_legacy_summary(SUMMARY_OUTPUT_PATH, manifest_data['sha256_hash'])\n    print(f\"Generated legacy summary: {SUMMARY_OUTPUT_PATH}\")\n    \n    print(\"Backup process completed successfully!\")\n\nif __name__ == \"__main__\":\n    main()\nEOF"]
[35.689376, "o", "size(tar_path)\r\n        \r\n        md5_hash = hashlib.md5()\r\n        sha256_hash = hashlib.sha256()\r\n        \r\n        with open(tar_path, 'rb') as f:\r\n            while True:\r\n                data = f.read(8192)\r\n                if not data:\r\n                    break\r\n                md5_hash.update(data)\r\n                sha256_hash.update(data)\r\n        \r\n        manifest_data = {\r\n            \"archive_name\": os.pat"]
[35.689396, "o", "h.basename(tar_path),\r\n            \"file_size_bytes\": file_size,\r\n        "]
[35.689417, "o", "    \"md5_hash\": md5_hash.hexdigest(),\r\n            \"sha256_hash\": sha256_hash.hexdigest(),\r\n            \"created_at_"]
[35.689449, "o", "utc\": datetime.datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')\r\n        }\r\n        \r\n        with open(manifest_path, 'w') as f:\r\n   "]
[35.68948, "o", "         json.dump(manifest_data, f, indent=2)\r\n        \r\n        return manifest_data\r\n    except Exception as e:\r\n        print(f\"Error generating manifest: {e}\")\r\n        sys.exit(1)\r\n\r\n\r\ndef generate_legacy_summary(summary_path, manifest_sha256):\r\n    "]
[35.689506, "o", "\"\"\"Generate the legacy summary file with ISO-8859-1 encoding and CRLF line endings\u001b[?2004h"]
[35.689536, "o", "> "]
[35.689607, "o", "#!/usr/bin/env python3\r\n\u001b[?2004l\r"]
[35.689628, "o", "\u001b[?2004h"]
[35.689646, "o", "> \"\"\""]
[35.689663, "o", "\r\n\u001b[?2004l\r"]
[35.689682, "o", "\u001b[?2004h> "]
[35.689766, "o", "Legacy System Backup Tool\r\n\u001b[?2004l\r"]
[35.689792, "o", "\u001b[?2004h> "]
[35.69002, "o", "Creates a gzip-compressed tarball of a directory with safety measures,\r\n\u001b[?2004l\r"]
[35.690044, "o", "\u001b[?2004h> "]
[35.690243, "o", "generates a JSON manifest, and creates a legacy summary file.\r\n\u001b[?2004l\r"]
[35.690262, "o", "\u001b[?2004h> "]
[35.690284, "o", "\"\"\"\r\n\u001b[?2004l\r"]
[35.69031, "o", "\u001b[?2004h> "]
[35.690366, "o", "import os\r\n\u001b[?2004l\r\u001b[?2004h"]
[35.690393, "o", "> "]
[35.690415, "o", "import sys\r\n\u001b[?2004l\r"]
[35.690439, "o", "\u001b[?2004h"]
[35.690463, "o", "> "]
[35.69052, "o", "import tarfile\r\n\u001b[?2004l\r"]
[35.690546, "o", "\u001b[?2004h> "]
[35.690593, "o", "import json\r\n\u001b[?2004l\r"]
[35.690616, "o", "\u001b[?2004h> "]
[35.690664, "o", "import hashlib\r\n\u001b[?2004l\r"]
[35.690678, "o", "\u001b[?2004h"]
[35.690697, "o", "> "]
[35.690735, "o", "import datetime\r\n\u001b[?2004l\r"]
[35.690747, "o", "\u001b[?2004h"]
[35.690764, "o", "> "]
[35.690793, "o", "import glob\r\n\u001b[?2004l\r"]
[35.690812, "o", "\u001b[?2004h> "]
[35.690846, "o", "import io\r\n\u001b[?2004l\r"]
[35.690864, "o", "\u001b[?2004h> "]
[35.69091, "o", "import shutil\r\n\u001b[?2004l\r"]
[35.690927, "o", "\u001b[?2004h"]
[35.690946, "o", "> \r\n\u001b[?2004l\r"]
[35.690961, "o", "\u001b[?2004h> "]
[35.691006, "o", "# Configuration\r\n\u001b[?2004l\r"]
[35.691019, "o", "\u001b[?2004h"]
[35.691032, "o", "> "]
[35.691179, "o", "SOURCE_DIR = \"/home/user/tickets/issue_20230815/\"\r\n\u001b[?2004l\r"]
[35.691194, "o", "\u001b[?2004h> "]
[35.691423, "o", "TAR_OUTPUT_PATH = \"/home/user/backups/support_issue_20230815_legacy.tar.gz\"\r\n\u001b[?2004l\r"]
[35.691443, "o", "\u001b[?2004h"]
[35.691547, "o", "> "]
[35.691651, "o", "MANIFEST_OUTPUT_PATH = \"/home/user/backups/backup_manifest.json\"\r\n\u001b[?2004l\r"]
[35.691666, "o", "\u001b[?2004h> "]
[35.691857, "o", "SUMMARY_OUTPUT_PATH = \"/home/user/backups/backup_summary.txt\"\r\n\u001b[?2004l\r"]
[35.69187, "o", "\u001b[?2004h"]
[35.691886, "o", "> "]
[35.691983, "o", "IGNORE_FILENAME = \".backupignore\"\r\n\u001b[?2004l\r"]
[35.692, "o", "\u001b[?2004h> "]
[35.692015, "o", "\r\n\u001b[?2004l\r"]
[35.69203, "o", "\u001b[?2004h> "]
[35.692129, "o", "def read_ignore_file(directory):\r\n\u001b[?2004l\r"]
[35.692145, "o", "\u001b[?2004h"]
[35.69216, "o", "> "]
[35.692298, "o", "    \"\"\"Read and parse the .backupignore file.\"\"\"\r\n\u001b[?2004l\r"]
[35.692315, "o", "\u001b[?2004h"]
[35.692332, "o", "> "]
[35.692392, "o", "    ignore_patterns = []\r\n\u001b[?2004l\r"]
[35.69241, "o", "\u001b[?2004h"]
[35.692426, "o", "> "]
[35.69262, "o", "    ignore_file_path = os.path.join(directory, IGNORE_FILENAME)\r\n\u001b[?2004l\r"]
[35.69264, "o", "\u001b[?2004h> "]
[35.692666, "o", "    try:\r\n\u001b[?2004l\r"]
[35.692684, "o", "\u001b[?2004h> "]
[35.692828, "o", "        with open(ignore_file_path, 'r') as f:\r\n\u001b[?2004l\r"]
[35.692847, "o", "\u001b[?2004h> "]
[35.692933, "o", "            for line in f:\r\n\u001b[?2004l\r"]
[35.692951, "o", "\u001b[?2004h> "]
[35.693062, "o", "                line = line.strip()\r\n\u001b[?2004l\r"]
[35.693083, "o", "\u001b[?2004h> "]
[35.693247, "o", "                if line and not line.startswith('#'):\r\n\u001b[?2004l\r"]
[35.693263, "o", "\u001b[?2004h"]
[35.693279, "o", "> "]
[35.69342, "o", "                    ignore_patterns.append(line)\r\n\u001b[?2004l\r"]
[35.693436, "o", "\u001b[?2004h"]
[35.693449, "o", "> "]
[35.693545, "o", "    except FileNotFoundError:\r\n\u001b[?2004l\r"]
[35.693558, "o", "\u001b[?2004h"]
[35.693574, "o", "> "]
[35.693686, "o", "        pass  # Ignore file not present\r\n\u001b[?2004l\r"]
[35.693706, "o", "\u001b[?2004h> "]
[35.69379, "o", "    return ignore_patterns\r\n\u001b[?2004l\r"]
[35.693803, "o", "\u001b[?2004h"]
[35.693818, "o", "> \r\n\u001b[?2004l\r"]
[35.693832, "o", "\u001b[?2004h> "]
[35.693976, "o", "def should_ignore_file(path, ignore_patterns):\r\n\u001b[?2004l\r"]
[35.69399, "o", "\u001b[?2004h"]
[35.69401, "o", "> "]
[35.694185, "o", "    \"\"\"Check if a file should be ignored based on patterns.\"\"\"\r\n\u001b[?2004l\r"]
[35.694197, "o", "\u001b[?2004h"]
[35.694211, "o", "> "]
[35.694316, "o", "    for pattern in ignore_patterns:\r\n\u001b[?2004l\r"]
[35.694335, "o", "\u001b[?2004h> "]
[35.694485, "o", "        if glob.fnmatch.fnmatch(path, pattern):\r\n\u001b[?2004l\r"]
[35.694499, "o", "\u001b[?2004h"]
[35.694514, "o", "> "]
[35.694583, "o", "            return True\r\n\u001b[?2004l\r"]
[35.694597, "o", "\u001b[?2004h"]
[35.694617, "o", "> "]
[35.694655, "o", "    return False\r\n\u001b[?2004l\r"]
[35.69467, "o", "\u001b[?2004h"]
[35.69469, "o", "> \r\n\u001b[?2004l\r"]
[35.694705, "o", "\u001b[?2004h> "]
[35.694888, "o", "def archive_directory(source_dir, tar_path, ignore_patterns):\r\n\u001b[?2004l\r"]
[35.694903, "o", "\u001b[?2004h"]
[35.694918, "o", "> "]
[35.695188, "o", "    \"\"\"Create a tarball with dereferenced symlinks, skipping broken and recursive symlinks.\"\"\"\r\n\u001b[?2004l\r"]
[35.695203, "o", "\u001b[?2004h"]
[35.695219, "o", "> "]
[35.695236, "o", "    try:\r\n\u001b[?2004l\r"]
[35.695253, "o", "\u001b[?2004h"]
[35.695267, "o", "> "]
[35.695415, "o", "        with tarfile.open(tar_path, \"w:gz\") as tar:\r\n\u001b[?2004l\r"]
[35.695432, "o", "\u001b[?2004h> "]
[35.695616, "o", "            for root, dirs, files in os.walk(source_dir):\r\n\u001b[?2004l\r"]
[35.695633, "o", "\u001b[?2004h> "]
[35.695822, "o", "                # Filter directories based on ignore patterns\r\n\u001b[?2004l\r"]
[35.695836, "o", "\u001b[?2004h"]
[35.695852, "o", "> "]
[35.696114, "o", "                dirs[:] = [d for d in dirs if not should_ignore_file(os.path.join(root, d), ignore_patterns)]\r\n\u001b[?2004l\r"]
[35.696127, "o", "\u001b[?2004h"]
[35.696141, "o", "> "]
[35.696178, "o", "                \r\n\u001b[?2004l\r"]
[35.696191, "o", "\u001b[?2004h> "]
[35.696281, "o", "                for file in files:\r\n\u001b[?2004l\r"]
[35.696295, "o", "\u001b[?2004h"]
[35.69631, "o", "> "]
[35.696438, "o", "                    full_path = os.path.join(root, file)\r\n\u001b[?2004l\r"]
[35.696452, "o", "\u001b[?2004h"]
[35.69647, "o", "> "]
[35.696517, "o", "                    \r\n\u001b[?2004l\r"]
[35.696532, "o", "\u001b[?2004h> "]
[35.696665, "o", "                    # Check if file should be ignored\r\n\u001b[?2004l\r"]
[35.696683, "o", "\u001b[?2004h> "]
[35.696853, "o", "                    if should_ignore_file(full_path, ignore_patterns):\r\n\u001b[?2004l\r"]
[35.696867, "o", "\u001b[?2004h"]
[35.696882, "o", "> "]
[35.696954, "o", "                        continue\r\n\u001b[?2004l\r"]
[35.696968, "o", "\u001b[?2004h"]
[35.696986, "o", "> "]
[35.697026, "o", "                    \r\n\u001b[?2004l\r"]
[35.697041, "o", "\u001b[?2004h"]
[35.697058, "o", "> "]
[35.697165, "o", "                    # Check for broken symlinks\r\n\u001b[?2004l\r"]
[35.697179, "o", "\u001b[?2004h"]
[35.697193, "o", "> "]
[35.697306, "o", "                    if os.path.islink(full_path):\r\n\u001b[?2004l\r"]
[35.697319, "o", "\u001b[?2004h"]
[35.697335, "o", "> "]
[35.697471, "o", "                        if not os.path.exists(full_path):\r\n\u001b[?2004l\r"]
[35.697485, "o", "\u001b[?2004h> "]
[35.69767, "o", "                            print(f\"Skipping broken symlink: {full_path}\")\r\n\u001b[?2004l\r"]
[35.697683, "o", "\u001b[?2004h"]
[35.697698, "o", "> "]
[35.697779, "o", "                            continue\r\n\u001b[?2004l\r"]
[35.697793, "o", "\u001b[?2004h"]
[35.697808, "o", "> "]
[35.697944, "o", "                        # Dereference symlink for inclusion\r\n\u001b[?2004l\r"]
[35.697957, "o", "\u001b[?2004h"]
[35.697974, "o", "> "]
[35.698117, "o", "                        file_path = os.path.realpath(full_path)\r\n\u001b[?2004l\r"]
[35.698133, "o", "\u001b[?2004h> "]
[35.698202, "o", "                    else:\r\n\u001b[?2004l\r"]
[35.698217, "o", "\u001b[?2004h> "]
[35.698333, "o", "                        file_path = full_path\r\n\u001b[?2004l\r"]
[35.698348, "o", "\u001b[?2004h"]
[35.698364, "o", "> "]
[35.698407, "o", "                    \r\n\u001b[?2004l\r"]
[35.698421, "o", "\u001b[?2004h"]
[35.698435, "o", "> "]
[35.698573, "o", "                    # Add file to archive (dereferenced)\r\n\u001b[?2004l\r"]
[35.698586, "o", "\u001b[?2004h"]
[35.698602, "o", "> "]
[35.698813, "o", "                    arcname = os.path.relpath(file_path, start=os.path.dirname(source_dir))\r\n\u001b[?2004l\r"]
[35.698827, "o", "\u001b[?2004h"]
[35.698841, "o", "> "]
[35.699008, "o", "                    tar.add(file_path, arcname=arcname, recursive=False)\r\n\u001b[?2004l\r"]
[35.699021, "o", "\u001b[?2004h"]
[35.699036, "o", "> "]
[35.699093, "o", "    except Exception as e:\r\n\u001b[?2004l\r"]
[35.699107, "o", "\u001b[?2004h"]
[35.699121, "o", "> "]
[35.699227, "o", "        print(f\"Error creating archive: {e}\")\r\n\u001b[?2004l\r"]
[35.699241, "o", "\u001b[?2004h"]
[35.699256, "o", "> "]
[35.699296, "o", "        sys.exit(1)\r\n\u001b[?2004l\r"]
[35.69931, "o", "\u001b[?2004h"]
[35.699324, "o", "> \r\n\u001b[?2004l\r"]
[35.699345, "o", "\u001b[?2004h> \r\n\u001b[?2004l\r"]
[35.699362, "o", "\u001b[?2004h> "]
[35.699484, "o", "def generate_manifest(tar_path, manifest_path):\r\n\u001b[?2004l\r"]
[35.699498, "o", "\u001b[?2004h> "]
[35.699643, "o", "    \"\"\"Generate a JSON manifest with archive metadata.\"\"\"\r\n\u001b[?2004l\r"]
[35.699657, "o", "\u001b[?2004h"]
[35.699673, "o", "> "]
[35.699687, "o", "    try:\r\n\u001b[?2004l\r"]
[35.6997, "o", "\u001b[?2004h"]
[35.69972, "o", "> "]
[35.699817, "o", "        file_size = os.path.getsize(tar_path)\r\n\u001b[?2004l\r"]
[35.699831, "o", "\u001b[?2004h"]
[35.699847, "o", "> "]
[35.699866, "o", "        \r\n\u001b[?2004l\r"]
[35.699881, "o", "\u001b[?2004h> "]
[35.69996, "o", "        md5_hash = hashlib.md5()\r\n\u001b[?2004l\r"]
[35.699975, "o", "\u001b[?2004h> "]
[35.700075, "o", "        sha256_hash = hashlib.sha256()\r\n\u001b[?2004l\r"]
[35.700089, "o", "\u001b[?2004h"]
[35.700104, "o", "> "]
[35.700122, "o", "        \r\n\u001b[?2004l\r"]
[35.700138, "o", "\u001b[?2004h> "]
[35.700235, "o", "        with open(tar_path, 'rb') as f:\r\n\u001b[?2004l\r"]
[35.700249, "o", "\u001b[?2004h"]
[35.700264, "o", "> "]
[35.700313, "o", "            while True:\r\n\u001b[?2004l\r"]
[35.700332, "o", "\u001b[?2004h"]
[35.700347, "o", "> "]
[35.700423, "o", "                data = f.read(8192)\r\n\u001b[?2004l\r"]
[35.700436, "o", "\u001b[?2004h"]
[35.700451, "o", "> "]
[35.700532, "o", "                if not data:\r\n\u001b[?2004l\r"]
[35.700558, "o", "\u001b[?2004h> "]
[35.700616, "o", "                    break\r\n\u001b[?2004l\r"]
[35.700633, "o", "\u001b[?2004h> "]
[35.700728, "o", "                md5_hash.update(data)\r\n\u001b[?2004l\r"]
[35.700746, "o", "\u001b[?2004h> "]
[35.700848, "o", "                sha256_hash.update(data)\r\n\u001b[?2004l\r"]
[35.700864, "o", "\u001b[?2004h> "]
[35.70089, "o", "        \r\n\u001b[?2004l\r"]
[35.700906, "o", "\u001b[?2004h> "]
[35.700976, "o", "        manifest_data = {\r\n\u001b[?2004l\r"]
[35.700994, "o", "\u001b[?2004h> "]
[35.701151, "o", "            \"archive_name\": os.path.basename(tar_path),\r\n\u001b[?2004l\r"]
[35.701172, "o", "\u001b[?2004h"]
[35.701188, "o", "> "]
[35.701288, "o", "            \"file_size_bytes\": file_size,\r\n\u001b[?2004l\r"]
[35.701304, "o", "\u001b[?2004h> "]
[35.701422, "o", "            \"md5_hash\": md5_hash.hexdigest(),\r\n\u001b[?2004l\r"]
[35.701818, "o", "\u001b[?2004h>             \"sha256_hash\": sha256_hash.hexdigest(),\r\n\u001b[?2004l\r\u001b[?2004h> "]
[35.701882, "o", "            \"created_at_utc\": datetime.datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')\r\n\u001b[?2004l\r\u001b[?2004h> "]
[35.701914, "o", "        }\r\n\u001b[?2004l\r"]
[35.701937, "o", "\u001b[?2004h> "]
[35.701971, "o", "        \r\n\u001b[?2004l\r"]
[35.701991, "o", "\u001b[?2004h> "]
[35.702115, "o", "        with open(manifest_path, 'w') as f:\r\n\u001b[?2004l\r"]
[35.702141, "o", "\u001b[?2004h> "]
[35.702268, "o", "            json.dump(manifest_data, f, indent=2)\r\n\u001b[?2004l\r"]
[35.70229, "o", "\u001b[?2004h> "]
[35.70232, "o", "        \r\n\u001b[?2004l\r"]
[35.702343, "o", "\u001b[?2004h> "]
[35.70243, "o", "        return manifest_data\r\n\u001b[?2004l\r"]
[35.702456, "o", "\u001b[?2004h> "]
[35.702544, "o", "    except Exception as e:\r\n\u001b[?2004l\r"]
[35.702566, "o", "\u001b[?2004h> "]
[35.702703, "o", "        print(f\"Error generating manifest: {e}\")\r\n\u001b[?2004l\r"]
[35.702725, "o", "\u001b[?2004h> "]
[35.702786, "o", "        sys.exit(1)\r\n\u001b[?2004l\r"]
[35.702808, "o", "\u001b[?2004h"]
[35.702832, "o", "> \r\n\u001b[?2004l\r\u001b[?2004h"]
[35.702855, "o", "> \r\n\u001b[?2004l\r"]
[35.702873, "o", "\u001b[?2004h> "]
[35.703029, "o", "def generate_legacy_summary(summary_path, manifest_sha256):\r\n\u001b[?2004l\r"]
[35.703053, "o", "\u001b[?2004h> "]
[35.703278, "o", "    \"\"\"Generate the legacy summary file with ISO-8859-1 encoding and CRLF line endings.\"\"\"\r\n\u001b[?2004l\r"]
[35.703297, "o", "\u001b[?2004h> "]
[35.703333, "o", "    try:\r\n"]
[35.703357, "o", "\u001b[?2004l\r\u001b[?2004h"]
[35.703375, "o", "> "]
[35.70353, "o", "        # Use latin-1 encoding and add CRLF line endings\r\n\u001b[?2004l\r"]
[35.703554, "o", "\u001b[?2004h> "]
[35.70383, "o", "        content = \"Legacy Backup Operation © 2023\\r\\nManifest SHA256: {hash}\\r\\n\".format(hash=manifest_sha256)\r\n\u001b[?2004l\r"]
[35.703852, "o", "\u001b[?2004h> "]
[35.703884, "o", "        \r\n\u001b[?2004l\r"]
[35.703903, "o", "\u001b[?2004h"]
[35.703922, "o", "> "]
[35.70403, "o", "        with open(summary_path, 'wb') as f:\r\n\u001b[?2004l\r"]
[35.704059, "o", "\u001b[?2004h"]
[35.704069, "o", "> "]
[35.704183, "o", "            f.write(content.encode('latin-1'))\r\n\u001b[?2004l\r"]
[35.704204, "o", "\u001b[?2004h> "]
[35.704282, "o", "    except Exception as e:\r\n\u001b[?2004l\r"]
[35.704303, "o", "\u001b[?2004h> "]
[35.704448, "o", "        print(f\"Error generating legacy summary: {e}\")\r\n\u001b[?2004l\r"]
[35.704479, "o", "\u001b[?2004h"]
[35.704498, "o", "> "]
[35.704547, "o", "        sys.exit(1)\r\n\u001b[?2004l\r"]
[35.704564, "o", "\u001b[?2004h"]
[35.704581, "o", "> \r\n\u001b[?2004l\r"]
[35.7046, "o", "\u001b[?2004h> "]
[35.704618, "o", "\r\n\u001b[?2004l\r"]
[35.704639, "o", "\u001b[?2004h> "]
[35.70467, "o", "def main():\r\n\u001b[?2004l\r"]
[35.704685, "o", "\u001b[?2004h"]
[35.704701, "o", "> "]
[35.704818, "o", "    print(\"Starting legacy backup process...\")\r\n\u001b[?2004l\r"]
[35.704834, "o", "\u001b[?2004h"]
[35.704852, "o", "> "]
[35.704868, "o", "    \r\n\u001b[?2004l\r"]
[35.704885, "o", "\u001b[?2004h> "]
[35.705018, "o", "    # Create backups directory if it doesn't exist\r\n\u001b[?2004l\r"]
[35.705037, "o", "\u001b[?2004h"]
[35.705053, "o", "> "]
[35.705188, "o", "    backups_dir = os.path.dirname(TAR_OUTPUT_PATH)\r\n\u001b[?2004l\r"]
[35.705209, "o", "\u001b[?2004h> "]
[35.705312, "o", "    if not os.path.exists(backups_dir):\r\n\u001b[?2004l\r"]
[35.705329, "o", "\u001b[?2004h"]
[35.705347, "o", "> "]
[35.705429, "o", "        os.makedirs(backups_dir)\r\n\u001b[?2004l\r"]
[35.705449, "o", "\u001b[?2004h> "]
[35.705595, "o", "        print(f\"Created directory: {backups_dir}\")\r\n\u001b[?2004l\r"]
[35.705618, "o", "\u001b[?2004h> "]
[35.705637, "o", "    \r\n\u001b[?2004l\r"]
[35.705657, "o", "\u001b[?2004h> "]
[35.705758, "o", "    # Check if source directory exists\r\n\u001b[?2004l\r"]
[35.70578, "o", "\u001b[?2004h> "]
[35.705881, "o", "    if not os.path.isdir(SOURCE_DIR):\r\n\u001b[?2004l\r"]
[35.705901, "o", "\u001b[?2004h> "]
[35.70607, "o", "        print(f\"Error: Source directory not found: {SOURCE_DIR}\")\r\n\u001b[?2004l\r"]
[35.70609, "o", "\u001b[?2004h> "]
[35.706147, "o", "        sys.exit(1)\r\n\u001b[?2004l\r"]
[35.706169, "o", "\u001b[?2004h> "]
[35.706187, "o", "    \r\n\u001b[?2004l\r"]
[35.706204, "o", "\u001b[?2004h"]
[35.706223, "o", "> "]
[35.706303, "o", "    # Read ignore file patterns\r\n\u001b[?2004l\r"]
[35.706323, "o", "\u001b[?2004h> "]
[35.706463, "o", "    ignore_patterns = read_ignore_file(SOURCE_DIR)\r\n\u001b[?2004l\r"]
[35.706486, "o", "\u001b[?2004h> "]
[35.706756, "o", "    print(f\"Loaded {len(ignore_patterns)} ignore patterns from {os.path.join(SOURCE_DIR, IGNORE_FILENAME)}\")\r\n\u001b[?2004l\r"]
[35.706784, "o", "\u001b[?2004h> "]
[35.706805, "o", "    \r\n\u001b[?2004l\r"]
[35.706823, "o", "\u001b[?2004h> "]
[35.706891, "o", "    # Create the archive\r\n\u001b[?2004l\r"]
[35.706911, "o", "\u001b[?2004h> "]
[35.707041, "o", "    print(f\"Creating archive: {TAR_OUTPUT_PATH}\")\r\n\u001b[?2004l\r"]
[35.70706, "o", "\u001b[?2004h"]
[35.707077, "o", "> "]
[35.707238, "o", "    archive_directory(SOURCE_DIR, TAR_OUTPUT_PATH, ignore_patterns)\r\n\u001b[?2004l\r"]
[35.707253, "o", "\u001b[?2004h"]
[35.70727, "o", "> "]
[35.70728, "o", "    \r\n\u001b[?2004l\r"]
[35.707303, "o", "\u001b[?2004h"]
[35.70732, "o", "> "]
[35.707381, "o", "    # Generate manifest\r\n\u001b[?2004l\r"]
[35.707399, "o", "\u001b[?2004h> "]
[35.70763, "o", "    manifest_data = generate_manifest(TAR_OUTPUT_PATH, MANIFEST_OUTPUT_PATH)\r\n\u001b[?2004l\r"]
[35.707654, "o", "\u001b[?2004h"]
[35.707671, "o", "> "]
[35.707799, "o", "    print(f\"Generated manifest: {MANIFEST_OUTPUT_PATH}\")\r\n\u001b[?2004l\r"]
[35.707815, "o", "\u001b[?2004h"]
[35.707831, "o", "> "]
[35.707981, "o", "    print(f\"Manifest SHA256: {manifest_data['sha256_hash']}\")\r\n\u001b[?2004l\r"]
[35.708001, "o", "\u001b[?2004h> "]
[35.708022, "o", "    \r\n\u001b[?2004l\r"]
[35.708039, "o", "\u001b[?2004h"]
[35.708055, "o", "> "]
[35.70813, "o", "    # Generate legacy summary\r\n\u001b[?2004l\r"]
[35.708148, "o", "\u001b[?2004h"]
[35.708164, "o", "> "]
[35.708353, "o", "    generate_legacy_summary(SUMMARY_OUTPUT_PATH, manifest_data['sha256_hash'])\r\n\u001b[?2004l\r"]
[35.708372, "o", "\u001b[?2004h"]
[35.708391, "o", "> "]
[35.708543, "o", "    print(f\"Generated legacy summary: {SUMMARY_OUTPUT_PATH}\")\r\n\u001b[?2004l\r"]
[35.708562, "o", "\u001b[?2004h> "]
[35.708584, "o", "    \r\n\u001b[?2004l\r"]
[35.708602, "o", "\u001b[?2004h"]
[35.708618, "o", "> "]
[35.708747, "o", "    print(\"Backup process completed successfully!\")\r\n\u001b[?2004l\r"]
[35.708766, "o", "\u001b[?2004h> "]
[35.708789, "o", "\r\n\u001b[?2004l\r\u001b[?2004h"]
[35.708805, "o", "> "]
[35.708876, "o", "if __name__ == \"__main__\":\r\n\u001b[?2004l\r"]
[35.708896, "o", "\u001b[?2004h> "]
[35.708934, "o", "    main()\r\n\u001b[?2004l\r"]
[35.708953, "o", "\u001b[?2004h"]
[35.70897, "o", "> EOF"]
[35.926706, "i", "python3 backup_tool.py\n"]
[35.926817, "o", "python3 backup_tool.py\r\n\u001b[?2004l\r"]
[35.926846, "o", "\u001b[?2004h"]
[35.926867, "o", "> "]
[45.898301, "i", "ls -la backups/\n"]
[45.898409, "o", "ls -la backups/\r\n"]
[45.89844, "o", "\u001b[?2004l\r"]
[45.898476, "o", "\u001b[?2004h> "]
[46.131792, "i", "echo \"=== Manifest Content ===\"\n"]
[46.131939, "o", "echo \"=== Manifest Content ===\"\r\n\u001b[?2004l\r"]
[46.131989, "o", "\u001b[?2004h> "]
[46.267732, "i", "cat backups/backup_manifest.json\n"]
[46.267909, "o", "cat backups/backup_manifest.json\r\n\u001b[?2004l\r"]
[46.267953, "o", "\u001b[?2004h> "]
[46.421168, "i", "echo \"=== Summary Content ===\"\n"]
[46.421286, "o", "echo \"=== Summary Content ===\"\r\n\u001b[?2004l\r"]
[46.421313, "o", "\u001b[?2004h"]
[46.421336, "o", "> "]
[46.540132, "i", "cat -v backups/backup_summary.txt\n"]
[46.540263, "o", "cat -v backups/backup_summary.txt\r\n"]
[46.540288, "o", "\u001b[?2004l\r"]
[46.540306, "o", "\u001b[?2004h> "]
[46.653332, "i", "file backups/backup_summary.txt\n"]
[46.653497, "o", "file backups/backup_summary.txt\r\n"]
[46.653528, "o", "\u001b[?2004l\r\u001b[?2004h"]
[46.65355, "o", "> "]
[52.314587, "i", "ls -la tickets/\n"]
[52.314679, "o", "ls -la tickets/\r\n\u001b[?2004l\r"]
[52.314723, "o", "\u001b[?2004h> "]
[52.42362, "i", "echo \"Source directory issue_20230815 not found. Backup task cannot be completed.\"\n"]
[52.423943, "o", "echo \"Source directory issue_20230815 not found. Backup task cannot be completed.\"\r\n\u001b[?2004l\r"]
[52.423978, "o", "\u001b[?2004h"]
[52.424004, "o", "> "]
