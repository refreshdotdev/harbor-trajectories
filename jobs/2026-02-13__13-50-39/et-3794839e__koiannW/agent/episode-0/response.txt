```json
{
  "analysis": "The system is currently in a clean state at the home directory of the root user. No prior work has been done for this MLOps migration task. The primary directories (/home/user/mlops/experiments/, /home/user/mlops/deprecated/, and /home/user/mlops/summary/) do not exist and must be created. The task requires processing legacy experiment logs with various encodings, applying data hygiene rules, handling status overrides, implementing exclusion policies, and generating specific output files.",
  "plan": "1. Create the necessary directory structure at /home/user/mlops. 2. Navigate to the working directory. 3. Begin implementing the Python script that will handle all aspects of the data processing and output generation as per the specifications.",
  "commands": [
    {
      "keystrokes": "mkdir -p /home/user/mlops/experiments\n",
      "duration": 0.1
    },
    {
      "keystrokes": "mkdir -p /home/user/mlops/deprecated\n",
      "duration": 0.1
    },
    {
      "keystrokes": "mkdir -p /home/user/mlops/summary\n",
      "duration": 0.1
    },
    {
      "keystrokes": "cd /home/user/mlops\n",
      "duration": 0.1
    },
    {
      "keystrokes": "cat > process_artifacts.py << 'EOF'\n#!/usr/bin/env python3\n\"\"\"\nMLOps Legacy Migration & Consolidation Script\n\"\"\"\nimport os\nimport sys\nimport glob\nimport hashlib\nimport re\nimport yaml\nfrom collections import defaultdict\nfrom datetime import datetime\n\ndef detect_encoding(file_path):\n    \"\"\"Detect file encoding with priority: UTF-16LE with BOM, Latin-1, UTF-8\"\"\"\n    with open(file_path, 'rb') as f:\n        raw_data = f.read(4096)  # Read initial chunk\n    \n    # Check for UTF-16LE BOM\n    if raw_data.startswith(b'\\xff\\xfe'):\n        return 'utf-16le'\n    \n    # Check if valid Latin-1 (always valid)\n    try:\n        raw_data.decode('latin-1')\n        return 'latin-1'\n    except UnicodeDecodeError:\n        pass\n    \n    # Check if valid UTF-8\n    try:\n        raw_data.decode('utf-8')\n        return 'utf-8'\n    except UnicodeDecodeError:\n        pass\n    \n    return None\n\ndef read_artifact_file(file_path):\n    \"\"\"Read artifact file with proper encoding handling\"\"\"\n    encoding = detect_encoding(file_path)\n    with open(file_path, 'r', encoding=encoding, errors='replace') as f:\n        return f.readlines()\n\ndef is_line_corrupted(line):\n    \"\"\"Check if line has odd number of trailing spaces\"\"\"\n    stripped_line = line.rstrip()\n    if stripped_line != line.rstrip(' '):\n        # Calculate trailing spaces\n        trailing_spaces = len(line) - len(stripped_line) - 1  # -1 for newline\n        return trailing_spaces % 2 != 0\n    return False\n\ndef parse_line(line):\n    \"\"\"Parse a valid log line\"\"\"\n    parts = line.rstrip().split('|')\n    if len(parts) >= 2:\n        artifact_name = parts[0].strip()\n        status = parts[1].strip()\n        return artifact_name, status, '|'.join(parts[2:]) if len(parts) > 2 else None\n    return None, None, None\n\ndef load_status_overrides(override_file):\n    \"\"\"Load status override mappings\"\"\"\n    overrides = {}\n    if os.path.exists(override_file):\n        with open(override_file, 'r') as f:\n            for line in f:\n                line = line.strip()\n                if line and not line.startswith('#'):\n                    if '=' in line:\n                        key, value = line.split('=', 1)\n                        overrides[key.strip()] = value.strip()\n    return overrides\n\ndef get_deprecated_names(deprecated_dir):\n    \"\"\"Get set of deprecated root names (case-insensitive)\"\"\"\n    deprecated = set()\n    if os.path.exists(deprecated_dir):\n        for filename in os.listdir(deprecated_dir):\n            if filename:\n                name, _ = os.path.splitext(filename)\n                if name:\n                    deprecated.add(name.lower())\n    return deprecated\n\ndef main():\n    # Configuration\n    experiments_dir = 'experiments'\n    deprecated_dir = 'deprecated'\n    summary_dir = 'summary'\n    \n    corruption_report_path = os.path.join(summary_dir, 'corruption_report.txt')\n    inventory_path = os.path.join(summary_dir, 'inventory.csv')\n    manifest_path = os.path.join(summary_dir, 'manifest.yaml')\n    \n    # Create summary directory\n    os.makedirs(summary_dir, exist_ok=True)\n    \n    # Initialize data structures\n    corrupted_lines = []\n    artifact_locations = defaultdict(list)\n    \n    # Get deprecated names (case-insensitive)\n    deprecated_names = get_deprecated_names(deprecated_dir)\n    \n    # Scan experiment directories\n    for exp_dir in os.listdir(experiments_dir):\n        exp_path = os.path.join(experiments_dir, exp_dir)\n        if os.path.isdir(exp_path):\n            artifact_files = glob.glob(os.path.join(exp_path, 'artifacts.*'))\n            \n            for artifact_file in artifact_files:\n                # Load status overrides if available\n                override_file = os.path.join(exp_path, 'status_override.map')\n                status_overrides = load_status_overrides(override_file)\n                \n                # Read artifact file with proper encoding\n                lines = read_artifact_file(artifact_file)\n                \n                for line in lines:\n                    # Skip empty lines\n                    if not line.strip():\n                        continue\n                        \n                    # Handle corrupted lines\n                    if is_line_corrupted(line):\n                        corrupted_lines.append(f\"{exp_dir}: {line.strip()}\")\n                        continue\n                        \n                    # Parse valid lines\n                    artifact_name, log_status, _ = parse_line(line)\n                    if artifact_name and log_status:\n                        # Apply status override if exists\n                        resolved_status = status_overrides.get(artifact_name, log_status)\n                        \n                        # Check exclusion policy\n                        root_name = os.path.splitext(artifact_name)[0].lower()\n                        if root_name in deprecated_names:\n                            continue\n                            \n                        # Filter for READY status\n                        if resolved_status == 'READY':\n                            # Record location\n                            rel_path = os.path.relpath(exp_path, '.').replace('\\\\', '/')\n                            artifact_locations[artifact_name].append(rel_path)\n    \n    # Write corruption report\n    with open(corruption_report_path, 'w', encoding='utf-8') as f:\n        f.write(\"\\n\".join(corrupted_lines))\n    \n    # Prepare inventory data\n    inventory_items = []\n    for artifact, locations in artifact_locations.items():\n        # Sort locations and remove duplicates while preserving order\n        sorted_locations = sorted(set(locations))\n        location_str = ';'.join(sorted_locations)\n        \n        # Calculate name hash\n        name_hash = hashlib.md5(artifact.strip().encode('utf-8')).hexdigest()\n        \n        inventory_items.append((artifact.strip(), name_hash, location_str))\n    \n    # Sort inventory alphabetically by artifact name (case-sensitive)\n    inventory_items.sort(key=lambda x: x[0])\n    \n    # Write inventory CSV\n    with open(inventory_path, 'w', encoding='utf-8') as f:\n        f.write(\"Artifact|NameHash|Locations\\n\")\n        for item in inventory_items:\n            f.write(f\"{item[0]}|{item[1]}|{item[2]}\\n\")\n    \n    # Prepare manifest data\n    manifest_data = {\n        'total_artifacts': len(inventory_items),\n        'generated_at': datetime.utcnow().strftime('%Y-%m-%d')\n    }\n    \n    # Calculate inventory hash\n    with open(inventory_path, 'rb') as f:\n        manifest_data['inventory_hash'] = hashlib.sha256(f.read()).hexdigest()\n    \n    # Write manifest YAML\n    with open(manifest_path, 'w', encoding='utf-8') as f:\n        yaml.safe_dump(manifest_data, f, default_flow_style=False)\n    \n    print(f\"Processing complete. Found {len(inventory_items)} artifacts.\")\n    print(f\"Corruption report: {corruption_report_path}\")\n    print(f\"Inventory report: {inventory_path}\")\n    print(f\"Manifest report: {manifest_path}\")\n\nif __name__ == '__main__':\n    main()\nEOF\n",
      "duration": 0.1
    },
    {
      "keystrokes": "chmod +x process_artifacts.py\n",
      "duration": 0.1
    }
  ],
  "task_complete": false
}
```