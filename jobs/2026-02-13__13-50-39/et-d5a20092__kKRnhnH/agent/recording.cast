{"version": 2, "width": 160, "height": 40, "timestamp": 1771009524, "env": {"SHELL": "/bin/bash", "TERM": "screen"}}
[0.006136, "o", "\u001b[?2004hroot@deae95a1-7828-4612-b53a-e96120a69026:/home/user# "]
[1.023951, "i", "clear\r"]
[1.024112, "o", "clear\r\n\u001b[?2004l\r"]
[1.025495, "o", "\u001b[H\u001b[J"]
[1.025697, "o", "\u001b[?2004h"]
[1.025724, "o", "root@deae95a1-7828-4612-b53a-e96120a69026:/home/user# "]
[12.30295, "i", "cd /home/user/capacity\n"]
[12.303069, "o", "cd /home/user/capacity\r\n\u001b[?2004l\r"]
[12.303211, "o", "\u001b[?2004h"]
[12.303263, "o", "root@deae95a1-7828-4612-b53a-e96120a69026:/home/user/capacity# "]
[12.493219, "i", "ls -la\n"]
[12.493341, "o", "ls -la\r\n\u001b[?2004l\r"]
[12.494902, "o", "total 0\r\n"]
[12.494952, "o", "drwxr-xr-x 1 user user 62 Feb 13 19:04 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 user user 93 Feb 13 19:04 \u001b[01;34m..\u001b[0m\r\ndrwxr-xr-x 1 user user 34 Feb 13 19:04 \u001b[01;34mconfig\u001b[0m\r\ndrwxr-xr-x 1 user user 81 Feb 13 19:04 \u001b[01;34mraw\u001b[0m\r\ndrwxr-xr-x 1 user user 10 Feb 13 19:04 \u001b[01;34mreports\u001b[0m\r\n"]
[12.495194, "o", "\u001b[?2004hroot@deae95a1-7828-4612-b53a-e96120a69026:/home/user/capacity# "]
[12.776251, "i", "cat config/manifest.txt\n"]
[12.776372, "o", "cat config/manifest.txt\r\n\u001b[?2004l\r"]
[12.777548, "o", "# Active Regions for Jan 2023\r\nregion_alpha\r\n# Region Gamma is deprecated\r\nregion_beta\r\n"]
[12.777728, "o", "\u001b[?2004hroot@deae95a1-7828-4612-b53a-e96120a69026:/home/user/capacity# "]
[12.949844, "i", "mkdir -p reports\n"]
[12.949956, "o", "mkdir -p reports\r\n\u001b[?2004l\r"]
[12.951469, "o", "\u001b[?2004hroot@deae95a1-7828-4612-b53a-e96120a69026:/home/user/capacity# "]
[13.203489, "i", "pytest -c pytest.ini --collect-only\n"]
[13.203668, "o", "pytest -c pytest.ini --collect-only\r\n\u001b[?2004l\r"]
[13.32481, "o", "Traceback (most recent call last):\r\n  File \"/usr/local/bin/pytest\", line 8, in <module>\r\n    sys.exit(console_main())\r\n  File \"/usr/local/lib/python3.10/dist-packages/_pytest/config/__init__.py\", line 223, in console_main\r\n    code = main()\r\n  File \"/usr/local/lib/python3.10/dist-packages/_pytest/config/__init__.py\", line 193, in main\r\n    config = _prepareconfig(new_args, plugins)\r\n  File \"/usr/local/lib/python3.10/dist-packages/_pytest/config/__init__.py\", line 361, in _prepareconfig\r\n    config: Config = pluginmanager.hook.pytest_cmdline_parse(\r\n  File \"/usr/local/lib/python3.10/dist-packages/pluggy/_hooks.py\", line 512, in __call__\r\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\r\n  File \"/usr/local/lib/python3.10/dist-packages/pluggy/_manager.py\", line 120, in _hookexec\r\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\r\n  File \"/usr/local/lib/python3.10/dist-packages/pluggy/_callers.py\", line 167, in _multicall\r\n    raise exception\r\n  File \"/usr/l"]
[13.324955, "o", "ocal/lib/python3.10/dist-packages/pluggy/_callers.py\", line 139, in _multicall\r\n    teardown.throw(exception)\r\n  File \"/usr/local/lib/python3.10/dist-packages/_pytest/helpconfig.py\", line 124, in pytest_cmdline_parse\r\n    config = yield\r\n  File \"/usr/local/lib/python3.10/dist-packages/pluggy/_callers.py\", line 121, in _multicall\r\n    res = hook_impl.function(*args)\r\n  File \"/usr/local/lib/python3.10/dist-packages/_pytest/config/__init__.py\", line 1186, in pytest_cmdline_parse\r\n    self.parse(args)\r\n  File \"/usr/local/lib/python3.10/dist-packages/_pytest/config/__init__.py\", line 1495, in parse\r\n    rootpath, inipath, inicfg, ignored_config_files = determine_setup(\r\n  File \"/usr/local/lib/python3.10/dist-packages/_pytest/config/findpaths.py\", line 309, in determine_setup\r\n    inicfg = load_config_dict_from_file(inipath_) or {}\r\n  File \"/usr/local/lib/python3.10/dist-packages/_pytest/config/findpaths.py\", line 67, in load_config_dict_from_file\r\n    iniconfig = _parse_ini_config(filepath)\r\n  File \"/usr/local/lib"]
[13.32504, "o", "/python3.10/dist-packages/_pytest/config/findpaths.py\", line 53, in _parse_ini_config\r\n    return iniconfig.IniConfig(str(path))\r\n  File \"/usr/local/lib/python3.10/dist-packages/iniconfig/__init__.py\", line 113, in __init__\r\n    with open(self.path, encoding=encoding) as fp:\r\nFileNotFoundError: [Errno 2] No such file or directory: '/home/user/capacity/pytest.ini'\r\n"]
[13.34039, "o", "\u001b[?2004h"]
[13.340422, "o", "root@deae95a1-7828-4612-b53a-e96120a69026:/home/user/capacity# "]
[85.220841, "i", "ls -la raw/\n"]
[85.220937, "o", "ls -la raw/\r\n\u001b[?2004l\r"]
[85.223331, "o", "total 0\r\n"]
[85.22338, "o", "drwxr-xr-x 1 user user 81 Feb 13 19:04 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 user user 62 Feb 13 19:04 \u001b[01;34m..\u001b[0m\r\n"]
[85.223405, "o", "drwxr-xr-x 1 user user 83 Feb 13 19:04 \u001b[01;34mregion_alpha\u001b[0m\r\ndrwxr-xr-x 1 user user 70 Feb 13 19:04 \u001b[01;34mregion_beta\u001b[0m\r\ndrwxr-xr-x 1 user user 40 Feb 13 19:04 \u001b[01;34mregion_gamma\u001b[0m\r\n"]
[85.223748, "o", "\u001b[?2004hroot@deae95a1-7828-4612-b53a-e96120a69026:/home/user/capacity# "]
[85.436728, "i", "find raw/ -name \"*_202301.log\" | head -5\n"]
[85.437073, "o", "find raw/ -name \"*_202301.log\" | head -5\r\n"]
[85.437125, "o", "\u001b[?2004l\r"]
[85.439867, "o", "raw/region_alpha/server1_legacy_202301.log\r\nraw/region_alpha/server2_maint_202301.log\r\nraw/region_beta/server3_202301.log\r\nraw/region_beta/server4_202301.log\r\nraw/region_gamma/server5_202301.log\r\n"]
[85.440303, "o", "\u001b[?2004h"]
[85.440345, "o", "root@deae95a1-7828-4612-b53a-e96120a69026:/home/user/capacity# "]
[85.899789, "i", "cat > process_capacity.py << 'EOF'\n#!/usr/bin/env python3\nimport os\nimport sys\nimport json\nimport re\nimport struct\nimport hashlib\nimport glob\nimport io\nfrom collections import defaultdict\n\n# ------------------- Configuration -------------------\nBASE_DIR = '/home/user/capacity'\nRAW_DIR = os.path.join(BASE_DIR, 'raw')\nREPORTS_DIR = os.path.join(BASE_DIR, 'reports')\n\n# ------------------- Helper Functions -------------------\n\ndef parse_manifest(manifest_path):\n    \"\"\"Parse manifest file, return list of active directories\"\"\"\n    active_dirs = []\n    try:\n        with open(manifest_path, 'r') as f:\n            for line in f:\n                line = line.strip()\n                if line and not line.startswith('#'):\n                    active_dirs.append(line)\n    except FileNotFoundError:\n        print(f\"Warning: Manifest file {manifest_path} not found\")\n    return active_dirs\n\ndef normalize_metric(val, is_legacy):\n    \"\"\"Convert to int: round floats, legacy already int\"\"\"\n    if is_legacy:\n        return int(val)\n "]
[85.899921, "i", "   else:\n        return round(float(val))\n\ndef load_file_with_encoding(file_path):\n    \"\"\"Try UTF-8 with BOM, then UTF-8, then ISO-8859-1\"\"\"\n    content = None\n    try:\n        # Try UTF-8 with BOM\n        with open(file_path, 'r', encoding='utf-8-sig') as f:\n            content = f.read()\n    except UnicodeDecodeError:\n        try:\n            # Try standard UTF-8\n            with open(file_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n        except UnicodeDecodeError:\n            try:\n                # Try ISO-8859-1\n                with open(file_path, 'r', encoding='iso-8859-1') as f:\n                    content = f.read()\n            except Exception as e:\n                print(f\"Error reading {file_path}: {e}\")\n    return content\n\ndef process_metrics(content, file_path):\n    \"\"\"Parse metrics from file content\"\"\"\n    if 'meta_status: active' not in content:\n        return None, None, None, None\n    \n    is_legacy = 'legacy' in file_path\n    cpu_vals, mem_vals, disk_vals = [], [],"]
[85.900001, "i", " []\n    \n    # Regex to find metric lines\n    for line in content.splitlines():\n        line = line.strip()\n        cpu_match = re.search(r'CPU_USED:\\s*(\\d+\\.?\\d*)', line)\n        mem_match = re.search(r'MEM_USED:\\s*(\\d+\\.?\\d*)', line)\n        disk_match = re.search(r'DISK_USED:\\s*(\\d+\\.?\\d*)', line)\n        \n        if cpu_match:\n            try:\n                cpu_val = normalize_metric(cpu_match.group(1), is_legacy)\n                if 5 <= cpu_val <= 95:\n                    cpu_vals.append(cpu_val)\n            except (ValueError, TypeError):\n                pass\n        \n        if mem_match:\n            try:\n                mem_val = normalize_metric(mem_match.group(1), is_legacy)\n                if 5 <= mem_val <= 95:\n                    mem_vals.append(mem_val)\n            except (ValueError, TypeError):\n                pass\n        \n        if disk_match:\n            try:\n                disk_val = normalize_metric(disk_match.group(1), is_legacy)\n                if 5 <= disk_val <= 95:\n               "]
[85.900084, "i", "     disk_vals.append(disk_val)\n            except (ValueError, TypeError):\n                pass\n    \n    return cpu_vals, mem_vals, disk_vals, is_legacy\n\ndef calculate_averages(cpu_vals, mem_vals, disk_vals):\n    \"\"\"Calculate averages rounded down\"\"\"\n    def safe_avg(vals):\n        return int(sum(vals) / len(vals)) if vals else 0\n    \n    return (\n        safe_avg(cpu_vals),\n        safe_avg(mem_vals),\n        safe_avg(disk_vals)\n    )\n\ndef create_summary_log(cpu_avg, mem_avg, disk_avg, json_size):\n    \"\"\"Create summary log with CRLF line endings\"\"\"\n    content = f\"AVG_CPU_USED={cpu_avg}\\r\\nAVG_MEM_USED={mem_avg}\\r\\nAVG_DISK_USED={disk_avg}\\r\\nsource_size={json_size}\\r\\n\"\n    return content\n\ndef create_binary_checksum(data):\n    \"\"\"Create binary MD5 checksum\"\"\"\n    return hashlib.md5(data.encode('utf-8')).digest()\n\ndef create_operations_log_entry(num_files, checksum_file_path):\n    \"\"\"Create operations log entry\"\"\"\n    checksum_data = open(checksum_file_path, 'rb').read()\n    sha256_hash = hashlib.sha256(che"]
[85.900119, "i", "cksum_data).hexdigest()\n    return f\"Publication 2023-01: {num_files} files, Checksum: {sha256_hash}\"\n\n# ------------------- Main Processing -------------------\n\ndef main():\n    print(\"Starting January 2023 capacity report generation...\")\n    \n    # 1. Parse manifest\n    manifest_path = os.path.join(BASE_DIR, 'config', 'manifest.txt')\n    active_dirs = parse_manifest(manifest_path)\n    print(f\"Found {len(active_dirs)} active directories: {active_dirs}\")\n    \n    # 2. Initialize aggregation\n    all_cpu_vals, all_mem_vals, all_disk_vals = [], [], []\n    valid_file_count = 0\n    \n    # 3. Process files\n    for active_dir in active_dirs:\n        dir_path = os.path.join(RAW_DIR, active_dir)\n        if not os.path.isdir(dir_path):\n            print(f\"Warning: Directory {dir_path} not found\")\n            continue\n        \n        # Find all matching files in this directory\n        pattern = os.path.join(dir_path, '*_202301.log')\n        for file_path in glob.glob(pattern):\n            print(f\"Processing {file_path}."]
[85.900146, "i", "..\")\n            content = load_file_with_encoding(file_path)\n            if not content:\n                continue\n            \n            cpu_vals, mem_vals, disk_vals, _ = process_metrics(content, file_path)\n            if None in [cpu_vals, mem_vals, disk_vals]:\n                continue\n            \n            all_cpu_vals.extend(cpu_vals)\n            all_mem_vals.extend(mem_vals)\n            all_disk_vals.extend(disk_vals)\n            valid_file_count += 1\n    \n    # 4. Calculate averages\n    cpu_avg, mem_avg, disk_avg = calculate_averages(all_cpu_vals, all_mem_vals, all_disk_vals)\n    print(f\"Calculated averages: CPU={cpu_avg}, MEM={mem_avg}, DISK={disk_avg}\")\n    \n    # 5. Generate intermediate.json\n    json_data = {\n        'AVG_CPU_USED': cpu_avg,\n        'AVG_MEM_USED': mem_avg,\n        'AVG_DISK_USED': disk_avg\n    }\n    json_str = json.dumps(json_data, separators=(',', ':'))\n    json_path = os.path.join(REPORTS_DIR, 'intermediate.json')\n    with open(json_path, 'w') as f:\n        f.write(json_str"]
[85.900174, "i", ")\n    json_size = os.path.getsize(json_path)\n    print(f\"Generated {json_path} ({json_size} bytes)\")\n    \n    # 6. Generate summary_202301.log\n    summary_content = create_summary_log(cpu_avg, mem_avg, disk_avg, json_size)\n    summary_path = os.path.join(REPORTS_DIR, 'summary_202301.log')\n    with open(summary_path, 'w', encoding='utf-8', newline='\\r\\n') as f:\n        f.write(summary_content)\n    print(f\"Generated {summary_path}\")\n    \n    # 7. Generate checksum.bin\n    checksum_data = create_binary_checksum(summary_content)\n    checksum_path = os.path.join(REPORTS_DIR, 'checksum.bin')\n    with open(checksum_path, 'wb') as f:\n        f.write(checksum_data)\n    print(f\"Generated {checksum_path}\")\n    \n    # 8. Update symlink\n    latest_link = os.path.join(BASE_DIR, 'latest')\n    try:\n        os.unlink(latest_link)\n    except FileNotFoundError:\n        pass\n    abs_summary_path = os.path.abspath(summary_path)\n    os.symlink(abs_summary_path, latest_link)\n    print(f\"Updated symlink: {latest_link} -> {abs_summar"]
[85.900228, "i", "y_path}\")\n    \n    # 9. Append to operations.log\n    log_entry = create_operations_log_entry(valid_file_count, checksum_path)\n    log_path = os.path.join(BASE_DIR, 'operations.log')\n    with open(log_path, 'a') as f:\n        f.write(log_entry + '\\n')\n    print(f\"Appended to {log_path}: {log_entry}\")\n    \n    print(\"Capacity report generation complete!\")\n\nif __name__ == '__main__':\n    main()\nEOF\n"]
[85.900249, "o", "cat > process_capacity.py << 'EOF'\r\n"]
[85.900289, "o", "\u001b[?2004l\r"]
[85.900362, "o", "\u001b[?2004h"]
[85.900416, "o", "> "]
[85.900633, "o", "#!/usr/bin/env python3\r\n\u001b[?2004l\r"]
[85.900694, "o", "\u001b[?2004h"]
[85.900742, "o", "> "]
[85.900821, "o", "import os\r\n\u001b[?2004l\r"]
[85.900873, "o", "\u001b[?2004h"]
[85.900918, "o", "> "]
[85.901026, "o", "import sys\r\n\u001b[?2004l\r"]
[85.90107, "o", "\u001b[?2004h> "]
[85.901221, "o", "import json\r\n\u001b[?2004l\r"]
[85.901267, "o", "\u001b[?2004h> "]
[85.901383, "o", "import re\r\n\u001b[?2004l\r"]
[85.901425, "o", "\u001b[?2004h"]
[85.901468, "o", "> "]
[85.901592, "o", "import struct\r\n\u001b[?2004l\r"]
[85.901635, "o", "\u001b[?2004h"]
[85.901682, "o", "> "]
[85.901803, "o", "import hashlib\r\n\u001b[?2004l\r"]
[85.901859, "o", "\u001b[?2004h"]
[85.901901, "o", "> "]
[85.901987, "o", "import glob\r\n\u001b[?2004l\r"]
[85.902032, "o", "\u001b[?2004h"]
[85.902074, "o", "> "]
[85.90216, "o", "import io\r\n\u001b[?2004l\r"]
[85.902216, "o", "\u001b[?2004h"]
[85.902258, "o", "> "]
[85.902543, "o", "from collections import defaultdict\r\n\u001b[?2004l\r"]
[85.902586, "o", "\u001b[?2004h"]
[85.902629, "o", "> \r\n\u001b[?2004l\r"]
[85.902673, "o", "\u001b[?2004h> "]
[85.903136, "o", "# ------------------- Configuration -------------------\r\n\u001b[?2004l\r"]
[85.903177, "o", "\u001b[?2004h"]
[85.903234, "o", "> "]
[85.903495, "o", "BASE_DIR = '/home/user/capacity'\r\n\u001b[?2004l\r"]
[85.903561, "o", "\u001b[?2004h> "]
[85.903911, "o", "RAW_DIR = os.path.join(BASE_DIR, 'raw')\r\n\u001b[?2004l\r"]
[85.903959, "o", "\u001b[?2004h> "]
[85.904369, "o", "REPORTS_DIR = os.path.join(BASE_DIR, 'reports')\r\n\u001b[?2004l\r"]
[85.904427, "o", "\u001b[?2004h> "]
[85.904474, "o", "\r\n\u001b[?2004l\r\u001b[?2004h"]
[85.904534, "o", "> "]
[85.90499, "o", "# ------------------- Helper Functions -------------------\r\n\u001b[?2004l\r"]
[85.905034, "o", "\u001b[?2004h"]
[85.905099, "o", "> \r\n\u001b[?2004l\r\u001b[?2004h"]
[85.905151, "o", "> "]
[85.905456, "o", "def parse_manifest(manifest_path):\r\n\u001b[?2004l\r"]
[85.905507, "o", "\u001b[?2004h"]
[85.90555, "o", "> "]
[85.906054, "o", "    \"\"\"Parse manifest file, return list of active directories\"\"\"\r\n\u001b[?2004l\r"]
[85.906098, "o", "\u001b[?2004h"]
[85.906146, "o", "> "]
[85.906331, "o", "    active_dirs = []\r\n\u001b[?2004l\r"]
[85.906395, "o", "\u001b[?2004h> "]
[85.906494, "o", "    try:\r\n\u001b[?2004l\r"]
[85.906546, "o", "\u001b[?2004h> "]
[85.906918, "o", "        with open(manifest_path, 'r') as f:\r\n\u001b[?2004l\r"]
[85.906965, "o", "\u001b[?2004h"]
[85.907011, "o", "> "]
[85.907228, "o", "            for line in f:\r\n\u001b[?2004l\r"]
[85.907264, "o", "\u001b[?2004h"]
[85.907302, "o", "> "]
[85.907586, "o", "                line = line.strip()\r\n\u001b[?2004l\r"]
[85.907619, "o", "\u001b[?2004h"]
[85.907657, "o", "> "]
[85.908076, "o", "                if line and not line.startswith('#'):\r\n\u001b[?2004l\r"]
[85.908123, "o", "\u001b[?2004h"]
[85.908173, "o", "> "]
[85.908527, "o", "                    active_dirs.append(line)\r\n\u001b[?2004l\r"]
[85.908562, "o", "\u001b[?2004h"]
[85.9086, "o", "> "]
[85.908846, "o", "    except FileNotFoundError:\r\n\u001b[?2004l\r"]
[85.908894, "o", "\u001b[?2004h> "]
[85.909565, "o", "        print(f\"Warning: Manifest file {manifest_path} not found\")\r\n\u001b[?2004l\r"]
[85.909614, "o", "\u001b[?2004h"]
[85.909652, "o", "> "]
[85.909832, "o", "    return active_dirs\r\n\u001b[?2004l\r"]
[85.909876, "o", "\u001b[?2004h"]
[85.909919, "o", "> \r\n\u001b[?2004l\r"]
[85.909952, "o", "\u001b[?2004h"]
[85.909985, "o", "> "]
[85.910292, "o", "def normalize_metric(val, is_legacy):\r\n\u001b[?2004l\r"]
[85.910333, "o", "\u001b[?2004h"]
[85.910395, "o", "> "]
[85.910835, "o", "    \"\"\"Convert to int: round floats, legacy already int\"\"\"\r\n\u001b[?2004l\r"]
[85.910874, "o", "\u001b[?2004h"]
[85.910907, "o", "> "]
[85.91108, "o", "    if is_legacy:\r\n\u001b[?2004l\r"]
[85.911131, "o", "\u001b[?2004h"]
[85.911174, "o", "> "]
[85.911397, "o", "        return int(val)\r\n\u001b[?2004l\r"]
[85.91144, "o", "\u001b[?2004h"]
[85.911486, "o", "> "]
[85.911572, "o", "    else:\r\n\u001b[?2004l\r"]
[85.911612, "o", "\u001b[?2004h"]
[85.911657, "o", "> "]
[85.911972, "o", "        return round(float(val))\r\n\u001b[?2004l\r"]
[85.912033, "o", "\u001b[?2004h> "]
[85.912077, "o", "\r\n\u001b[?2004l\r"]
[85.912114, "o", "\u001b[?2004h> "]
[85.912536, "o", "def load_file_with_encoding(file_path):\r\n\u001b[?2004l\r"]
[85.912578, "o", "\u001b[?2004h> "]
[85.91315, "o", "    \"\"\"Try UTF-8 with BOM, then UTF-8, then ISO-8859-1\"\"\"\r\n\u001b[?2004l\r"]
[85.913207, "o", "\u001b[?2004h"]
[85.913253, "o", "> "]
[85.913383, "o", "    content = None\r\n\u001b[?2004l\r"]
[85.913423, "o", "\u001b[?2004h> "]
[85.913525, "o", "    try:\r\n\u001b[?2004l\r"]
[85.913565, "o", "\u001b[?2004h"]
[85.91361, "o", "> "]
[85.913837, "o", "        # Try UTF-8 with BOM\r\n\u001b[?2004l\r"]
[85.913877, "o", "\u001b[?2004h"]
[85.913928, "o", "> "]
[85.914411, "o", "        with open(file_path, 'r', encoding='utf-8-sig') as f:\r\n\u001b[?2004l\r"]
[85.914451, "o", "\u001b[?2004h"]
[85.914492, "o", "> "]
[85.914716, "o", "            content = f.read()\r\n"]
[85.914743, "o", "\u001b[?2004l\r"]
[85.914762, "o", "\u001b[?2004h"]
[85.914782, "o", "> "]
[85.915078, "o", "    except UnicodeDecodeError:\r\n"]
[85.915095, "o", "\u001b[?2004l\r"]
[85.915119, "o", "\u001b[?2004h"]
[85.915167, "o", "> "]
[85.915286, "o", "        try:\r\n\u001b[?2004l\r"]
[85.915336, "o", "\u001b[?2004h"]
[85.915377, "o", "> "]
[85.915627, "o", "            # Try standard UTF-8\r\n\u001b[?2004l\r"]
[85.915668, "o", "\u001b[?2004h"]
[85.915718, "o", "> "]
[85.916198, "o", "            with open(file_path, 'r', encoding='utf-8') as f:\r\n\u001b[?2004l\r"]
[85.916249, "o", "\u001b[?2004h"]
[85.916291, "o", "> "]
[85.916555, "o", "                content = f.read()\r\n\u001b[?2004l\r"]
[85.916596, "o", "\u001b[?2004h"]
[85.916654, "o", "> "]
[85.916913, "o", "        except UnicodeDecodeError:\r\n\u001b[?2004l\r"]
[85.916954, "o", "\u001b[?2004h"]
[85.916993, "o", "> "]
[85.917131, "o", "            try:\r\n\u001b[?2004l\r"]
[85.917171, "o", "\u001b[?2004h"]
[85.917218, "o", "> "]
[85.917482, "o", "                # Try ISO-8859-1\r\n\u001b[?2004l\r"]
[85.917523, "o", "\u001b[?2004h"]
[85.917575, "o", "> "]
[85.91811, "o", "                with open(file_path, 'r', encoding='iso-8859-1') as f:\r\n\u001b[?2004l\r"]
[85.918151, "o", "\u001b[?2004h"]
[85.918204, "o", "> "]
[85.918506, "o", "                    content = f.read()\r\n\u001b[?2004l\r"]
[85.918548, "o", "\u001b[?2004h"]
[85.918594, "o", "> "]
[85.918876, "o", "            except Exception as e:\r\n\u001b[?2004l\r"]
[85.918933, "o", "\u001b[?2004h"]
[85.918972, "o", "> "]
[85.919419, "o", "                print(f\"Error reading {file_path}: {e}\")\r\n\u001b[?2004l\r"]
[85.919461, "o", "\u001b[?2004h"]
[85.919513, "o", "> "]
[85.919653, "o", "    return content\r\n\u001b[?2004l\r"]
[85.919694, "o", "\u001b[?2004h"]
[85.919733, "o", "> \r\n\u001b[?2004l\r"]
[85.919773, "o", "\u001b[?2004h"]
[85.919812, "o", "> "]
[85.92013, "o", "def process_metrics(content, file_path):\r\n\u001b[?2004l\r"]
[85.920171, "o", "\u001b[?2004h"]
[85.920227, "o", "> "]
[85.920648, "o", "    \"\"\"Parse metrics from file content\"\"\"\r\n\u001b[?2004l\r"]
[85.920684, "o", "\u001b[?2004h"]
[85.920718, "o", "> "]
[85.921154, "o", "    if 'meta_status: active' not in content:\r\n\u001b[?2004l\r"]
[85.921187, "o", "\u001b[?2004h"]
[85.92122, "o", "> "]
[85.921599, "o", "        return None, None, None, None\r\n"]
[85.92162, "o", "\u001b[?2004l\r"]
[85.92164, "o", "\u001b[?2004h"]
[85.921661, "o", "> "]
[85.921705, "o", "    "]
[85.921724, "o", "\r\n\u001b[?2004l\r"]
[85.921744, "o", "\u001b[?2004h"]
[85.92177, "o", "> "]
[85.922143, "o", "    is_legacy = 'legacy' in file_path\r\n"]
[85.922161, "o", "\u001b[?2004l\r"]
[85.922179, "o", "\u001b[?2004h"]
[85.922211, "o", "> "]
[85.922672, "o", "    cpu_vals, mem_vals, disk_vals = [], [], []\r\n\u001b[?2004l\r"]
[85.922707, "o", "\u001b[?2004h"]
[85.922731, "o", "> "]
[85.922794, "o", "    \r\n\u001b[?2004l\r"]
[85.922831, "o", "\u001b[?2004h"]
[85.922863, "o", "> "]
[85.923129, "o", "    # Regex to find metric lines\r\n\u001b[?2004l\r"]
[85.923171, "o", "\u001b[?2004h"]
[85.92323, "o", "> "]
[85.923517, "o", "    for line in content.splitlines():\r\n\u001b[?2004l\r"]
[85.923563, "o", "\u001b[?2004h"]
[85.923602, "o", "> "]
[85.92382, "o", "        line = line.strip()\r\n\u001b[?2004l\r"]
[85.923862, "o", "\u001b[?2004h"]
[85.923901, "o", "> "]
[85.924403, "o", "        cpu_match = re.search(r'CPU_USED:\\s*(\\d+\\.?\\d*)', line)\r\n\u001b[?2004l\r"]
[85.924445, "o", "\u001b[?2004h"]
[85.924483, "o", "> "]
[85.924971, "o", "        mem_match = re.search(r'MEM_USED:\\s*(\\d+\\.?\\d*)', line)\r\n\u001b[?2004l\r"]
[85.925026, "o", "\u001b[?2004h"]
[85.925066, "o", "> "]
[85.92559, "o", "        disk_match = re.search(r'DISK_USED:\\s*(\\d+\\.?\\d*)', line)\r\n\u001b[?2004l\r"]
[85.925632, "o", "\u001b[?2004h"]
[85.925655, "o", "> "]
[85.925758, "o", "        \r\n\u001b[?2004l\r"]
[85.925808, "o", "\u001b[?2004h"]
[85.925851, "o", "> "]
[85.926015, "o", "        if cpu_match:\r\n\u001b[?2004l\r"]
[85.926089, "o", "\u001b[?2004h> "]
[85.926275, "o", "            try:\r\n\u001b[?2004l\r"]
[85.926318, "o", "\u001b[?2004h"]
[85.926349, "o", "> "]
[85.926918, "o", "                cpu_val = normalize_metric(cpu_match.group(1), is_legacy)\r\n\u001b[?2004l\r"]
[85.926961, "o", "\u001b[?2004h"]
[85.927, "o", "> "]
[85.927326, "o", "                if 5 <= cpu_val <= 95:\r\n\u001b[?2004l\r"]
[85.927369, "o", "\u001b[?2004h"]
[85.927408, "o", "> "]
[85.927748, "o", "                    cpu_vals.append(cpu_val)\r\n\u001b[?2004l\r"]
[85.927789, "o", "\u001b[?2004h"]
[85.927827, "o", "> "]
[85.928168, "o", "            except (ValueError, TypeError):\r\n\u001b[?2004l\r"]
[85.928221, "o", "\u001b[?2004h"]
[85.928263, "o", "> "]
[85.928426, "o", "                pass\r\n\u001b[?2004l\r"]
[85.928467, "o", "\u001b[?2004h"]
[85.928521, "o", "> "]
[85.928586, "o", "        \r\n\u001b[?2004l\r"]
[85.928627, "o", "\u001b[?2004h"]
[85.928667, "o", "> "]
[85.928844, "o", "        if mem_match:\r\n\u001b[?2004l\r"]
[85.928888, "o", "\u001b[?2004h"]
[85.928918, "o", "> "]
[85.92906, "o", "            try:\r\n\u001b[?2004l\r"]
[85.929106, "o", "\u001b[?2004h"]
[85.929147, "o", "> "]
[85.92972, "o", "                mem_val = normalize_metric(mem_match.group(1), is_legacy)\r\n\u001b[?2004l\r"]
[85.929765, "o", "\u001b[?2004h"]
[85.929822, "o", "> "]
[85.930114, "o", "                if 5 <= mem_val <= 95:\r\n\u001b[?2004l\r"]
[85.930159, "o", "\u001b[?2004h"]
[85.930218, "o", "> "]
[85.93056, "o", "                    mem_vals.append(mem_val)\r\n\u001b[?2004l\r"]
[85.930604, "o", "\u001b[?2004h"]
[85.93064, "o", "> "]
[85.930977, "o", "            except (ValueError, TypeError):\r\n\u001b[?2004l\r"]
[85.931022, "o", "\u001b[?2004h"]
[85.931052, "o", "> "]
[85.931232, "o", "                pass\r\n\u001b[?2004l\r"]
[85.931273, "o", "\u001b[?2004h"]
[85.931313, "o", "> "]
[85.931391, "o", "        \r\n\u001b[?2004l\r"]
[85.931436, "o", "\u001b[?2004h"]
[85.93147, "o", "> "]
[85.931655, "o", "        if disk_match:\r\n\u001b[?2004l\r"]
[85.931696, "o", "\u001b[?2004h"]
[85.931729, "o", "> "]
[85.93187, "o", "            try:\r\n\u001b[?2004l\r"]
[85.931913, "o", "\u001b[?2004h"]
[85.931953, "o", "> "]
[85.932547, "o", "                disk_val = normalize_metric(disk_match.group(1), is_legacy)\r\n\u001b[?2004l\r"]
[85.932592, "o", "\u001b[?2004h"]
[85.93262, "o", "> "]
[85.932937, "o", "                if 5 <= disk_val <= 95:\r\n\u001b[?2004l\r"]
[85.932978, "o", "\u001b[?2004h"]
[85.93302, "o", "> "]
[85.933395, "o", "                    disk_vals.append(disk_val)\r\n\u001b[?2004l\r"]
[85.933436, "o", "\u001b[?2004h"]
[85.933464, "o", "> "]
[85.93381, "o", "            except (ValueError, TypeError):\r\n\u001b[?2004l\r"]
[85.933854, "o", "\u001b[?2004h"]
[85.933884, "o", "> "]
[85.934054, "o", "                pass\r\n\u001b[?2004l\r"]
[85.934108, "o", "\u001b[?2004h"]
[85.934135, "o", "> "]
[85.981973, "o", "    \r\n\u001b[?2004l\r\u001b[?2004h>     return cpu_vals, mem_vals, disk_vals, is_legacy\r\n\u001b[?2004l\r\u001b[?2004h> \r\n\u001b[?2004l\r\u001b[?2004h> def calculate_averages(cpu_vals, mem_vals, disk_vals):\r\n\u001b[?2004l\r\u001b[?2004h>     \"\"\"Calculate averages rounded down\"\"\"\r\n\u001b[?2004l\r\u001b[?2004h>     def safe_avg(vals):\r\n\u001b[?2004l\r\u001b[?2004h>         return int(sum(vals) / len(vals)) if vals else 0\r\n\u001b[?2004l\r\u001b[?2004h>     \r\n\u001b[?2004l\r\u001b[?2004h>     return (\r\n\u001b[?2004l\r\u001b[?2004h>         safe_avg(cpu_vals),\r\n\u001b[?2004l\r\u001b[?2004h>         safe_avg(mem_vals),\r\n\u001b[?2004l\r\u001b[?2004h>         safe_avg(disk_vals)\r\n\u001b[?2004l\r\u001b[?2004h>     )\r\n\u001b[?2004l\r\u001b[?2004h> \r\n\u001b[?2004l\r\u001b[?2004h> def create_summary_log(cpu_avg, mem_avg, disk_avg, json_size):\r\n\u001b[?2004l\r\u001b[?2004h> "]
[85.982113, "o", "    \"\"\"Create summary log with CRLF line endings\"\"\"\r\n\u001b[?2004l\r"]
[85.982183, "o", "\u001b[?2004h"]
[85.982244, "o", "> "]
[85.983056, "o", "    content = f\"AVG_CPU_USED={cpu_avg}\\r\\nAVG_MEM_USED={mem_avg}\\r\\nAVG_DISK_USED={disk_avg}\\r\\nsource_size={json_size}\\r\\n\"\r\n\u001b[?2004l\r"]
[85.983115, "o", "\u001b[?2004h> "]
[85.983266, "o", "    return content\r\n\u001b[?2004l\r"]
[85.98333, "o", "\u001b[?2004h> \r\n\u001b[?2004l\r"]
[85.9834, "o", "\u001b[?2004h> "]
[85.983607, "o", "def create_binary_checksum(data):\r\n\u001b[?2004l\r"]
[85.98369, "o", "\u001b[?2004h> "]
[85.983912, "o", "    \"\"\"Create binary MD5 checksum\"\"\"\r\n\u001b[?2004l\r"]
[85.983963, "o", "\u001b[?2004h"]
[85.984011, "o", "> "]
[85.984338, "o", "    return hashlib.md5(data.encode('utf-8')).digest()\r\n\u001b[?2004l\r"]
[85.984383, "o", "\u001b[?2004h"]
[85.984433, "o", "> \r\n\u001b[?2004l\r"]
[85.98448, "o", "\u001b[?2004h> "]
[85.984875, "o", "def create_operations_log_entry(num_files, checksum_file_path):\r\n\u001b[?2004l\r"]
[85.984917, "o", "\u001b[?2004h"]
[85.984966, "o", "> "]
[85.985279, "o", "    \"\"\"Create operations log entry\"\"\"\r\n\u001b[?2004l\r\u001b[?2004h> "]
[85.985652, "o", "    checksum_data = open(checksum_file_path, 'rb').read()\r\n\u001b[?2004l\r"]
[85.985693, "o", "\u001b[?2004h"]
[85.985742, "o", "> "]
[85.986115, "o", "    sha256_hash = hashlib.sha256(checksum_data).hexdigest()\r\n\u001b[?2004l\r"]
[85.986159, "o", "\u001b[?2004h> "]
[85.986686, "o", "    return f\"Publication 2023-01: {num_files} files, Checksum: {sha256_hash}\"\r\n\u001b[?2004l\r"]
[85.986733, "o", "\u001b[?2004h> "]
[85.986781, "o", "\r\n\u001b[?2004l\r\u001b[?2004h"]
[85.986836, "o", "> "]
[85.987218, "o", "# ------------------- Main Processing -------------------\r\n\u001b[?2004l\r"]
[85.987278, "o", "\u001b[?2004h"]
[85.987389, "o", "> \r\n\u001b[?2004l\r\u001b[?2004h> "]
[85.987464, "o", "def main():\r\n\u001b[?2004l\r"]
[85.98753, "o", "\u001b[?2004h> "]
[85.987952, "o", "    print(\"Starting January 2023 capacity report generation...\")\r\n\u001b[?2004l\r"]
[85.987995, "o", "\u001b[?2004h"]
[85.988039, "o", "> "]
[85.988066, "o", "    \r\n\u001b[?2004l\r"]
[85.988306, "o", "\u001b[?2004h>     # 1. Parse manifest\r\n"]
[85.988367, "o", "\u001b[?2004l\r\u001b[?2004h"]
[85.988396, "o", "> "]
[85.988855, "o", "    manifest_path = os.path.join(BASE_DIR, 'config', 'manifest.txt')\r\n\u001b[?2004l\r"]
[85.988907, "o", "\u001b[?2004h"]
[85.988953, "o", "> "]
[85.989275, "o", "    active_dirs = parse_manifest(manifest_path)\r\n\u001b[?2004l\r"]
[85.989325, "o", "\u001b[?2004h> "]
[85.989811, "o", "    print(f\"Found {len(active_dirs)} active directories: {active_dirs}\")\r\n\u001b[?2004l\r"]
[85.98988, "o", "\u001b[?2004h> "]
[85.989935, "o", "    \r\n\u001b[?2004l\r"]
[85.989965, "o", "\u001b[?2004h"]
[85.990038, "o", "> "]
[85.990246, "o", "    # 2. Initialize aggregation\r\n\u001b[?2004l\r"]
[85.990323, "o", "\u001b[?2004h"]
[85.990343, "o", "> "]
[85.990802, "o", "    all_cpu_vals, all_mem_vals, all_disk_vals = [], [], []\r\n"]
[85.990814, "o", "\u001b[?2004l\r"]
[85.990865, "o", "\u001b[?2004h"]
[85.990911, "o", "> "]
[85.99111, "o", "    valid_file_count = 0\r\n"]
[85.991123, "o", "\u001b[?2004l\r"]
[85.991184, "o", "\u001b[?2004h"]
[85.991208, "o", "> "]
[85.991302, "o", "    \r\n\u001b[?2004l\r\u001b[?2004h"]
[85.99135, "o", "> "]
[85.991487, "o", "    # 3. Process files\r\n"]
[85.991498, "o", "\u001b[?2004l\r"]
[85.991557, "o", "\u001b[?2004h> "]
[85.991819, "o", "    for active_dir in active_dirs:\r\n\u001b[?2004l\r"]
[85.991859, "o", "\u001b[?2004h"]
[85.991898, "o", "> "]
[85.992272, "o", "        dir_path = os.path.join(RAW_DIR, active_dir)\r\n"]
[85.992283, "o", "\u001b[?2004l\r"]
[85.992339, "o", "\u001b[?2004h> "]
[85.992613, "o", "        if not os.path.isdir(dir_path):\r\n\u001b[?2004l\r"]
[85.992694, "o", "\u001b[?2004h> "]
[85.993136, "o", "            print(f\"Warning: Directory {dir_path} not found\")\r\n\u001b[?2004l\r"]
[85.99326, "o", "\u001b[?2004h> "]
[85.993355, "o", "            continue\r\n\u001b[?2004l\r"]
[85.993402, "o", "\u001b[?2004h> "]
[85.993476, "o", "        \r\n"]
[85.993525, "o", "\u001b[?2004l\r\u001b[?2004h"]
[85.993571, "o", "> "]
[85.99388, "o", "        # Find all matching files in this directory\r\n\u001b[?2004l\r"]
[85.993925, "o", "\u001b[?2004h"]
[85.993968, "o", "> "]
[85.994377, "o", "        pattern = os.path.join(dir_path, '*_202301.log')\r\n\u001b[?2004l\r"]
[85.994426, "o", "\u001b[?2004h"]
[85.994482, "o", "> "]
[85.994751, "o", "        for file_path in glob.glob(pattern):\r\n\u001b[?2004l\r"]
[85.994797, "o", "\u001b[?2004h"]
[85.994838, "o", "> "]
[85.99513, "o", "            print(f\"Processing {file_path}...\")\r\n\u001b[?2004l\r"]
[85.995174, "o", "\u001b[?2004h"]
[85.995229, "o", "> "]
[85.995574, "o", "            content = load_file_with_encoding(file_path)\r\n\u001b[?2004l\r"]
[85.995665, "o", "\u001b[?2004h> "]
[85.995831, "o", "            if not content:\r\n\u001b[?2004l\r"]
[85.995894, "o", "\u001b[?2004h> "]
[85.996067, "o", "                continue\r\n\u001b[?2004l\r"]
[85.996116, "o", "\u001b[?2004h"]
[85.996176, "o", "> "]
[85.996255, "o", "            \r\n\u001b[?2004l\r"]
[85.996298, "o", "\u001b[?2004h"]
[85.996342, "o", "> "]
[85.99685, "o", "            cpu_vals, mem_vals, disk_vals, _ = process_metrics(content, file_path)\r\n\u001b[?2004l\r"]
[85.996896, "o", "\u001b[?2004h"]
[85.996938, "o", "> "]
[85.997296, "o", "            if None in [cpu_vals, mem_vals, disk_vals]:\r\n\u001b[?2004l\r"]
[85.99735, "o", "\u001b[?2004h> "]
[85.997533, "o", "                continue\r\n\u001b[?2004l\r"]
[85.997579, "o", "\u001b[?2004h> "]
[85.997689, "o", "            \r\n\u001b[?2004l\r"]
[85.997744, "o", "\u001b[?2004h"]
[85.99779, "o", "> "]
[85.998025, "o", "            all_cpu_vals.extend(cpu_vals)\r\n\u001b[?2004l\r"]
[85.998065, "o", "\u001b[?2004h"]
[85.998111, "o", "> "]
[85.998369, "o", "            all_mem_vals.extend(mem_vals)\r\n\u001b[?2004l\r"]
[85.99841, "o", "\u001b[?2004h"]
[85.998456, "o", "> "]
[85.998733, "o", "            all_disk_vals.extend(disk_vals)\r\n\u001b[?2004l\r"]
[85.998785, "o", "\u001b[?2004h> "]
[85.999019, "o", "            valid_file_count += 1\r\n\u001b[?2004l\r"]
[85.999067, "o", "\u001b[?2004h> "]
[85.99912, "o", "    \r\n\u001b[?2004l\r"]
[85.999166, "o", "\u001b[?2004h"]
[85.99922, "o", "> "]
[85.999452, "o", "    # 4. Calculate averages\r\n\u001b[?2004l\r"]
[85.999507, "o", "\u001b[?2004h"]
[85.999546, "o", "> "]
[85.999949, "o", "    cpu_avg, mem_avg, disk_avg = calculate_averages(all_cpu_vals, all_mem_vals, all_disk_vals)\r\n\u001b[?2004l\r"]
[86.00001, "o", "\u001b[?2004h> "]
[86.00047, "o", "    print(f\"Calculated averages: CPU={cpu_avg}, MEM={mem_avg}, DISK={disk_avg}\")\r\n\u001b[?2004l\r"]
[86.000528, "o", "\u001b[?2004h> "]
[86.000569, "o", "    \r\n\u001b[?2004l\r"]
[86.000618, "o", "\u001b[?2004h> "]
[86.000874, "o", "    # 5. Generate intermediate.json\r\n\u001b[?2004l\r\u001b[?2004h"]
[86.000921, "o", "> "]
[86.001024, "o", "    json_data = {\r\n\u001b[?2004l\r"]
[86.001073, "o", "\u001b[?2004h> "]
[86.001303, "o", "        'AVG_CPU_USED': cpu_avg,\r\n\u001b[?2004l\r"]
[86.001348, "o", "\u001b[?2004h> "]
[86.001497, "o", "        'AVG_MEM_USED': mem_avg,\r\n\u001b[?2004l\r"]
[86.001543, "o", "\u001b[?2004h> "]
[86.001681, "o", "        'AVG_DISK_USED': disk_avg\r\n\u001b[?2004l\r"]
[86.001727, "o", "\u001b[?2004h> "]
[86.001769, "o", "    }\r\n\u001b[?2004l\r\u001b[?2004h"]
[86.00181, "o", "> "]
[86.002063, "o", "    json_str = json.dumps(json_data, separators=(',', ':'))\r\n\u001b[?2004l\r"]
[86.002104, "o", "\u001b[?2004h> "]
[86.002398, "o", "    json_path = os.path.join(REPORTS_DIR, 'intermediate.json')\r\n\u001b[?2004l\r"]
[86.002418, "o", "\u001b[?2004h"]
[86.002468, "o", "> "]
[86.002602, "o", "    with open(json_path, 'w') as f:\r\n\u001b[?2004l\r"]
[86.002641, "o", "\u001b[?2004h> "]
[86.002757, "o", "        f.write(json_str)\r\n\u001b[?2004l\r"]
[86.002798, "o", "\u001b[?2004h> "]
[86.002983, "o", "    json_size = os.path.getsize(json_path)\r\n\u001b[?2004l\r"]
[86.003024, "o", "\u001b[?2004h> "]
[86.003277, "o", "    print(f\"Generated {json_path} ({json_size} bytes)\")\r\n\u001b[?2004l\r"]
[86.003322, "o", "\u001b[?2004h> "]
[86.003334, "o", "    \r\n\u001b[?2004l\r"]
[86.003384, "o", "\u001b[?2004h> "]
[86.003547, "o", "    # 6. Generate summary_202301.log\r\n\u001b[?2004l\r"]
[86.003582, "o", "\u001b[?2004h"]
[86.003593, "o", "> "]
[86.003948, "o", "    summary_content = create_summary_log(cpu_avg, mem_avg, disk_avg, json_size)\r\n\u001b[?2004l\r"]
[86.003999, "o", "\u001b[?2004h> "]
[86.004303, "o", "    summary_path = os.path.join(REPORTS_DIR, 'summary_202301.log')\r\n\u001b[?2004l\r"]
[86.004352, "o", "\u001b[?2004h> "]
[86.004659, "o", "    with open(summary_path, 'w', encoding='utf-8', newline='\\r\\n') as f:\r\n\u001b[?2004l\r"]
[86.004703, "o", "\u001b[?2004h> "]
[86.004846, "o", "        f.write(summary_content)\r\n\u001b[?2004l\r"]
[86.004891, "o", "\u001b[?2004h> "]
[86.005067, "o", "    print(f\"Generated {summary_path}\")\r\n\u001b[?2004l\r"]
[86.005105, "o", "\u001b[?2004h> "]
[86.005145, "o", "    \r\n\u001b[?2004l\r"]
[86.005184, "o", "\u001b[?2004h> "]
[86.005337, "o", "    # 7. Generate checksum.bin\r\n\u001b[?2004l\r"]
[86.00538, "o", "\u001b[?2004h"]
[86.005423, "o", "> "]
[86.005643, "o", "    checksum_data = create_binary_checksum(summary_content)\r\n\u001b[?2004l\r"]
[86.005686, "o", "\u001b[?2004h> "]
[86.005972, "o", "    checksum_path = os.path.join(REPORTS_DIR, 'checksum.bin')\r\n\u001b[?2004l\r"]
[86.006022, "o", "\u001b[?2004h> "]
[86.006211, "o", "    with open(checksum_path, 'wb') as f:\r\n\u001b[?2004l\r"]
[86.006261, "o", "\u001b[?2004h> "]
[86.006375, "o", "        f.write(checksum_data)\r\n\u001b[?2004l\r"]
[86.006419, "o", "\u001b[?2004h"]
[86.006461, "o", "> "]
[86.006595, "o", "    print(f\"Generated {checksum_path}\")\r\n\u001b[?2004l\r"]
[86.006635, "o", "\u001b[?2004h> "]
[86.006674, "o", "    \r\n\u001b[?2004l\r"]
[86.006714, "o", "\u001b[?2004h> "]
[86.006821, "o", "    # 8. Update symlink\r\n\u001b[?2004l\r"]
[86.00686, "o", "\u001b[?2004h> "]
[86.007083, "o", "    latest_link = os.path.join(BASE_DIR, 'latest')\r\n\u001b[?2004l\r"]
[86.007123, "o", "\u001b[?2004h> "]
[86.007169, "o", "    try:\r\n\u001b[?2004l\r"]
[86.007218, "o", "\u001b[?2004h> "]
[86.007363, "o", "        os.unlink(latest_link)\r\n\u001b[?2004l\r"]
[86.007403, "o", "\u001b[?2004h> "]
[86.007536, "o", "    except FileNotFoundError:\r\n\u001b[?2004l\r"]
[86.007576, "o", "\u001b[?2004h> "]
[86.007639, "o", "        pass\r\n\u001b[?2004l\r"]
[86.007679, "o", "\u001b[?2004h> "]
[86.007923, "o", "    abs_summary_path = os.path.abspath(summary_path)\r\n\u001b[?2004l\r"]
[86.007968, "o", "\u001b[?2004h> "]
[86.008175, "o", "    os.symlink(abs_summary_path, latest_link)\r\n\u001b[?2004l\r"]
[86.008226, "o", "\u001b[?2004h> "]
[86.008514, "o", "    print(f\"Updated symlink: {latest_link} -> {abs_summary_path}\")\r\n\u001b[?2004l\r"]
[86.008554, "o", "\u001b[?2004h> "]
[86.008593, "o", "    \r\n\u001b[?2004l\r"]
[86.008633, "o", "\u001b[?2004h> "]
[86.00878, "o", "    # 9. Append to operations.log\r\n\u001b[?2004l\r"]
[86.008819, "o", "\u001b[?2004h> "]
[86.009166, "o", "    log_entry = create_operations_log_entry(valid_file_count, checksum_path)\r\n\u001b[?2004l\r"]
[86.00922, "o", "\u001b[?2004h> "]
[86.00946, "o", "    log_path = os.path.join(BASE_DIR, 'operations.log')\r\n\u001b[?2004l\r"]
[86.0095, "o", "\u001b[?2004h> "]
[86.009667, "o", "    with open(log_path, 'a') as f:\r\n\u001b[?2004l\r"]
[86.009714, "o", "\u001b[?2004h> "]
[86.009859, "o", "        f.write(log_entry + '\\n')\r\n\u001b[?2004l\r"]
[86.009905, "o", "\u001b[?2004h> "]
[86.010127, "o", "    print(f\"Appended to {log_path}: {log_entry}\")\r\n\u001b[?2004l\r"]
[86.010168, "o", "\u001b[?2004h> "]
[86.010235, "o", "    \r\n\u001b[?2004l\r\u001b[?2004h> "]
[86.010475, "o", "    print(\"Capacity report generation complete!\")\r\n\u001b[?2004l\r"]
[86.010517, "o", "\u001b[?2004h> \r\n\u001b[?2004l\r"]
[86.010556, "o", "\u001b[?2004h> "]
[86.010693, "o", "if __name__ == '__main__':\r\n\u001b[?2004l\r"]
[86.010732, "o", "\u001b[?2004h> "]
[86.010793, "o", "    main()\r\n\u001b[?2004l\r"]
[86.010833, "o", "\u001b[?2004h> "]
[86.010871, "o", "EOF\r\n\u001b[?2004l\r"]
[86.013768, "o", "\u001b[?2004hroot@deae95a1-7828-4612-b53a-e96120a69026:/home/user/capacity# "]
[87.943824, "i", "python3 process_capacity.py\n"]
[87.944019, "o", "python3 process_capacity.py\r\n\u001b[?2004l\r"]
[87.969915, "o", "Starting January 2023 capacity report generation...\r\n"]
[87.970044, "o", "Found 2 active directories: ['region_alpha', 'region_beta']\r\n"]
[87.970221, "o", "Processing /home/user/capacity/raw/region_alpha/server1_legacy_202301.log...\r\n"]
[87.971292, "o", "Processing /home/user/capacity/raw/region_alpha/server2_maint_202301.log...\r\n"]
[87.971438, "o", "Processing /home/user/capacity/raw/region_beta/server3_202301.log...\r\n"]
[87.971498, "o", "Processing /home/user/capacity/raw/region_beta/server4_202301.log...\r\n"]
[87.971552, "o", "Calculated averages: CPU=0, MEM=0, DISK=0\r\n"]
[87.972565, "o", "Generated /home/user/capacity/reports/intermediate.json (53 bytes)\r\n"]
[87.972673, "o", "Generated /home/user/capacity/reports/summary_202301.log\r\n"]
[87.972774, "o", "Generated /home/user/capacity/reports/checksum.bin\r\n"]
[87.972871, "o", "Updated symlink: /home/user/capacity/latest -> /home/user/capacity/reports/summary_202301.log\r\n"]
[87.973061, "o", "Appended to /home/user/capacity/operations.log: Publication 2023-01: 3 files, Checksum: ed22cdc0a156d92050b6dc57f7437bea8128ab75cbf3dac1eafbe8c655dd6d8e\r\nCapacity report generation complete!\r\n"]
[87.977043, "o", "\u001b[?2004hroot@deae95a1-7828-4612-b53a-e96120a69026:/home/user/capacity# "]
[93.020063, "i", "ls -la reports/\n"]
[93.020285, "o", "ls -la reports/\r\n\u001b[?2004l\r"]
[93.021962, "o", "total 12\r\n"]
[93.021991, "o", "drwxr-xr-x 1 user user  93 Feb 13 19:06 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 user user 104 Feb 13 19:06 \u001b[01;34m..\u001b[0m\r\n-rw-r--r-- 1 root root  16 Feb 13 19:06 checksum.bin\r\n-rw-r--r-- 1 root root  53 Feb 13 19:06 intermediate.json\r\n-rw-r--r-- 1 root root  69 Feb 13 19:06 summary_202301.log\r\n"]
[93.022357, "o", "\u001b[?2004h"]
[93.022386, "o", "root@deae95a1-7828-4612-b53a-e96120a69026:/home/user/capacity# "]
[93.199723, "i", "cat reports/intermediate.json\n"]
[93.200041, "o", "cat reports/intermediate.json\r\n\u001b[?2004l\r"]
[93.201318, "o", "{\"AVG_CPU_USED\":0,\"AVG_MEM_USED\":0,\"AVG_DISK_USED\":0}"]
[93.201606, "o", "\u001b[?2004h"]
[93.201634, "o", "root@deae95a1-7828-4612-b53a-e96120a69026:/home/user/capacity# "]
[93.391086, "i", "head -4 reports/summary_202301.log\n"]
[93.391322, "o", "head -4 reports/summary_202301.log\r\n\u001b[?2004l\r"]
[93.393407, "o", "AVG_CPU_USED=0\r\r\r\nAVG_MEM_USED=0\r\r\r\nAVG_DISK_USED=0\r\r\r\nsource_size=53\r\r\r\n"]
[93.393727, "o", "\u001b[?2004hroot@deae95a1-7828-4612-b53a-e96120a69026:/home/user/capacity# "]
[93.671528, "i", "hexdump -C reports/checksum.bin\n"]
[93.67167, "o", "hexdump -C reports/checksum.bin\r\n\u001b[?2004l\r"]
[93.672137, "o", "bash: hexdump: command not found\r\n"]
[93.672424, "o", "\u001b[?2004h"]
[93.672443, "o", "root@deae95a1-7828-4612-b53a-e96120a69026:/home/user/capacity# "]
[94.046725, "i", "tail -1 operations.log\n"]
[94.047006, "o", "tail -1 operations.log\r\n\u001b[?2004l\r"]
[94.0484, "o", "Publication 2023-01: 3 files, Checksum: ed22cdc0a156d92050b6dc57f7437bea8128ab75cbf3dac1eafbe8c655dd6d8e\r\n"]
[94.048665, "o", "\u001b[?2004h"]
[94.048714, "o", "root@deae95a1-7828-4612-b53a-e96120a69026:/home/user/capacity# "]
