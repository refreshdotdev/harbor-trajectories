[?2004hroot@0069f637-be91-467f-80c8-8631f22d31b5:/home/user# asciinema rec --stdin /logs/agent/recording.cast
[?2004l[0;32masciinema: recording asciicast to /logs/agent/recording.cast[0m
[0;32masciinema: press <ctrl-d> or type "exit" when you're done[0m
[?2004hroot@0069f637-be91-467f-80c8-8631f22d31b5:/home/user# clear
[?2004l[H[J[?2004hroot@0069f637-be91-467f-80c8-8631f22d31b5:/home/user# mkdir -m 0700 /home/user/audit_2023Q4
[?2004l[?2004hroot@0069f637-be91-467f-80c8-8631f22d31b5:/home/user# export AUDIT_DATE="$(date -u +'%Y%m%d')"
[?2004l[?2004hroot@0069f637-be91-467f-80c8-8631f22d31b5:/home/user# export LOG_FILE="/home/user/audit_2023Q4/checksum_audit.log"
[?2004l[?2004hroot@0069f637-be91-467f-80c8-8631f22d31b5:/home/user# export SUMMARY_FILE="/home/user/audit_2023Q4/summary.json"
[?2004l[?2004hroot@0069f637-be91-467f-80c8-8631f22d31b5:/home/user# export SECRET_FILE="/home/user/source_files/.secret"
[?2004l[?2004hroot@0069f637-be91-467f-80c8-8631f22d31b5:/home/user# export SOURCE_DIR="/home/user/source_files"
[?2004l[?2004hroot@0069f637-be91-467f-80c8-8631f22d31b5:/home/user# export START_TIME="$(date -u --iso-8601=seconds)"
[?2004l[?2004hroot@0069f637-be91-467f-80c8-8631f22d31b5:/home/user# cat > generate_artifact_list.sh << 'EOF'
[?2004l[?2004h> #!/bin/bash
[?2004l[?2004h> set -euo pipefail
[?2004l[?2004h> 
[?2004l[?2004h> SOURCE_DIR="${SOURCE_DIR}"
[?2004l[?2004h> LOG_FILE="${LOG_FILE}"
[?2004l[?2004h> 
[?2004l[?2004h> # Function to check if a file is a valid artifact based on its properties
[?2004l[?2004h> is_valid_artifact() {
[?2004l[?2004h>   local file_path="$1"
[?2004l[?2004h>   local filename="$(basename "${file_path}")"
[?2004l[?2004h>   
[?2004l[?2004h>   if [[ "${filename}" == .* ]]; then
[?2004l[?2004h>     return 1 # Exclude hidden files
[?2004l[?2004h>   fi
[?2004l[?2004h>   
[?2004l[?2004h>   if [[ "${filename}" == *.txt ]]; then
[?2004l[?2004h>     return 0 # Text files (any size)
[?2004l[?2004h>   fi
[?2004l[?2004h>   
[?2004l[?2004h>   if [[ ! -f "${file_path}" ]]; then
[?2004l[?2004h>     return 1 # Not a regular file (e.g. broken symlink, dir, etc.)
[?2004l[?2004h>   fi
[?2004l[?2004h>   
[?2004l[?2004h>   if [[ $(stat -c%s "${file_path}") -ge 1024 ]]; then
[?2004l[?2004h>     return 0 # Other regular files >= 1KB
[?2004l[?2004h>   fi
[?2004l[?2004h>   
[?2004l[?2004h>   return 1 # Not a valid artifact
[?2004l[?2004h> }
[?2004l[?2004h> 
[?2004l[?2004h> # Prepare file records
[?2004l[?2004h> find "${SOURCE_DIR}" -mindepth 1 -maxdepth 1 \( ! -name '.*' \) -type f -print0 | while IFS= read -r -d '' filepath; do
[?2004l[?2004h>   # Resolve symlinks, skip broken ones
[?2004l[?2004h>   resolved_path="$(readlink -f "${filepath}" 2>/dev/null || true)"
[?2004l[?2004h>   if [[ -z "${resolved_path}" && ! -e "${filepath}" ]]; then
[?2004l[?2004h>     continue # Skip broken symlinks (readlink failed and original path doesn't exist)
[?2004l[?2004h>   fi
[?2004l[?2004h>   
[?2004l[?2004h>   # Use the symlink's name for logging if it's valid, otherwise use the file itself
[?2004l[?2004h>   log_filename="${filepath##*/}"
[?2004l[?2004h>   target_file_to_check="${resolved_path:-${filepath}}"
[?2004l[?2004h> 
[?2004l[?2004h>   if [[ ! -f "${target_file_to_check}" ]]; then
[?2004l[?2004h>     continue # Ensure target is a regular file (e.g. skip if symlink points to a dir)
[?2004l[?2004h>   fi
[?2004l[?2004h> 
[?2004l[?2004h>   if is_valid_artifact "${target_file_to_check}"; then
[?2004l[?2004h>     # Calculate hashes for the target file's content
[?2004l[?2004h>     sha256_hash=$(sha256sum "${target_file_to_check}" | cut -d' ' -f1)
[?2004l[?2004h>     md5_hash=$(md5sum "${target_file_to_check}" | cut -d' ' -f1)
[?2004l[?2004h>     
[?2004l[?2004h>     # Output in the required format for sorting
[?2004l[?2004h>     echo "${log_filename} SHA256=${sha256_hash}  MD5=${md5_hash}"
[?2004l[?2004h>   fi
[?2004l[?2004h> done
[?2004l[?2004h> EOFchmod +x generate_artifact_list.sh
[?2004l[?2004h> ./generate_artifact_list.sh | LC_ALL=C sort > /tmp/audit_file_records.txt
[?2004l[?2004h> cat > /tmp/audit_log_header.txt << EOF
[?2004l[?2004h> START       : 2023-Q4 checksum verification
[?2004l[?2004h> START_TIME  : ${START_TIME}
[?2004l[?2004h> 
[?2004l[?2004h> FILE_RECORDS
[?2004l[?2004h> EOFcat /tmp/audit_log_header.txt /tmp/audit_file_records.txt > "${LOG_FILE}.tmp_content_utf8"
[?2004l[?2004h> iconv -f UTF-8 -t ISO-8859-1 "${LOG_FILE}.tmp_content_utf8" > "${LOG_FILE}"
[?2004l[?2004h> rm /tmp/audit_file_records.txt /tmp/audit_log_header.txt generate_artifact_list.sh "${LOG_FILE}.tmp_content_utf8"
[?2004l[?2004h> export LOG_CHECKSUM="$(sha256sum "${LOG_FILE}" | cut -d' ' -f1)"
[?2004l[?2004h> export SECRET_CONTENT="$(cat "${SECRET_FILE}" | tr -d '[:space:]\n\r')"
[?2004l[?2004h> export HMAC_KEY="${SECRET_CONTENT}${AUDIT_DATE}"
[?2004l[?2004h> export SIGNATURE="$(echo -n "$(cat "${LOG_FILE}")" | hmacsha256 -k "${HMAC_KEY}" | cut -d' ' -f2)"
[?2004l[?2004h> export END_TIME_FOR_JSON="${START_TIME}"
[?2004l[?2004h> export FILE_COUNT="$(grep '^FILE_RECORDS' -n "${LOG_FILE}" | cut -d':' -f1 | awk '{print $1}')"
[?2004l[?2004h> export TOTAL_BYTES="0"
[?2004l[?2004h> cat > generate_json_summary.py << 'EOF'
[?2004l[?2004h> #!/usr/bin/env python3
[?2004l[?2004h> import json
[?2004l[?2004h> import sys
[?2004l[?2004h> 
[?2004l[?2004h> summary_data = {
[?2004l[?2004h>     "period": "2023-Q4",
[?2004l[?2004h>     "file_count": int(sys.argv[1]) if sys.argv[1].isdigit() else 0,
[?2004l[?2004h>     "total_bytes": int(sys.argv[2]),
[?2004l[?2004h>     "start_time": sys.argv[3],
[?2004l[?2004h>     "end_time": sys.argv[4],
[?2004l[?2004h>     "status": "COMPLETED",
[?2004l[?2004h>     "log_checksum": sys.argv[5],
[?2004l[?2004h>     "signature": sys.argv[6]
[?2004l[?2004h> }
[?2004l[?2004h> 
[?2004l[?2004h> with open(sys.argv[7], 'w', encoding='utf-8') as f:
[?2004l[?2004h>     json.dump(summary_data, f, indent=2)
[?2004l[?2004h> EOFpython3 generate_json_summary.py "${FILE_COUNT}" "${TOTAL_BYTES}" "${START_TIME}" "${END_TIME_FOR_JSON}" "${LOG_CHECKSUM}" "${SIGNATURE}" "${SUMMARY_FILE}" M[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K"
[?2004l[?2004h> rm generate_json_summary.py
[?2004l[?2004h> cat > verify_log.py << 'EOF'
[?2004l[?2004h> #!/usr/bin/env python3
[?2004l[?2004h> import sys
[?2004l[?2004h> import hashlib
[?2004l[?2004h> import codecs
[?2004l[?2004h> import os
[?2004l[?2004h> 
[?2004l[?2004h> log_file_path = sys.argv[1]
[?2004l[?2004h> verification_status = "VERIFICATION_PASSED"
[?2004l[?2004h> 
[?2004l[?2004h> try:
[?2004l[?2004h>     # Read log file content (ISO-8859-1) after the FILE_RECORDS line
[?2004l[?2004h>     with open(log_file_path, 'r', encoding='iso-8859-1') as f:
[?2004l[?2004h>         lines = f.readlines()
[?2004l[?2004h> 
[?2004l[?2004h>     # Find the line number of FILE_RECORDS to start parsing actual records
[?2004l[?2004h>     file_records_start_index = -1
[?2004l{[?2004h>     for i, line in enumerate(lines):
[?2004l[?2004h>         if line.strip() == "FILE_RECORDS":
[?2004l[?2004h>             file_records_start_index = i + 1 # Records start on the next line
[?2004l[?2004h>             break
[?2004l [?2004h>             
[?2004l[?2004h>     if file_records_start_index == -1 or file_records_start_index >= len(lines):
[?2004l[?2004h>         # No records or FILE_RECORDS not found as expected
[?2004l[?2004h>         verification_status = "VERIFICATION_FAILED - No records or FILE_RECORDS line issue"
[?2004l[?2004h>         print(f"Verification status: {verification_status}") # For debugging
[?2004l[?2004h>     else:
[?2004l[?2004h>         all_ok = True
[?2004l[?2004h>         for i in range(file_records_start_index, len(lines)):
[?2004l[?2004h>             line = lines[i].strip()
[?2004l[?2004h>             if not line or line.startswith("END_TIME") or line.startswith("END"): # Stop at footer
[?2004l[?2004h>                 break
[?2004l[?2004h>                 
[?2004l[?2004h>             if not line: continue # Skip empty lines within records
[?2004l[?2004h>             
[?2004l[?2004h>             parts = line.split()
[?2004l[?2004h>             if len(parts) < 4: # Basic format check
[?2004l[?2004h>                 all_ok = False
[?2004l[?2004h>                 verification_status = "VERIFICATION_FAILED"
[?2004l[?2004h>                 print(f"Failed to parse line: {line}") # For debugging
[?2004l[?2004h>                 break
[?2004l[?2004h>             
[?2004l[?2004h>             filename = parts[0]
[?2004l[?2004h>             expected_sha256 = parts[2] # parts[1] is SHA256=
[?2004l[?2004h>             
[?2004l[?2004h>             # Ensure filename refers to a file within the source directory context
[?2004l[?2004h>             # The log stores the original filename from audit directory list
[?2004l[?2004h>             file_to_check_path = os.path.join("${SOURCE_DIR}", filename)
[?2004l[?2004h>             
[?2004l[?2004h>             if not os.path.exists(file_to_check_path):
[?2004l[?2004h>                 all_ok = False
[?2004l[?2004h>                 verification_status = "VERIFICATION_FAILED"
[?2004l[?2004h>                 print(f"File not found for verification: {filename}") # For debugging
[?2004l[?2004h>                 break
[?2004l[?2004h>             
[?2004l[?2004h>             # Read file content in binary mode for hashing
[?2004l[?2004h>             with open(file_to_check_path, 'rb') as f_check:
[?2004l[?2004h>                 file_content = f_check.read()
[?2004l[?2004h>                 
[?2004l[?2004h>             calculated_sha256 = hashlib.sha256(file_content).hexdigest()
[?2004l[?2004h>             
[?2004l[?2004h>             if calculated_sha256 != expected_sha256:
[?2004l[?2004h>                 all_ok = False
[?2004l[?2004h>                 verification_status = "VERIFICATION_FAILED"
[?2004l[?2004h>                 print(f"Hash mismatch for {filename}: expected {expected_sha256}, got {calculated_sha256}") # For debugging
[?2004l[?2004h>                 break
[?2004l[?2004h>         
[?2004l[?2004h>         if not all_ok:
[?2004l[?2004h>             verification_status = "VERIFICATION_FAILED"
[?2004l[?2004h>             
[?2004l[?2004h>     # Append verification status line
[?2004l[?2004h>     with open(log_file_path, 'a', encoding='iso-8859-1') as f:
[?2004l[?2004h>         f.write(f"{verification_status}\n")
[?2004l[?2004h>         
[?2004l[?2004h>     # Also append END_TIME and END lines if they are not present yet
[?2004l[?2004h>     # (They should be, if the log was constructed as per spec)
[?2004l[?2004h>     # For robustness, check and append if missing.
[?2004l[?2004h>     last_lines = []
[?2004l[?2004h>     with open(log_file_path, 'r', encoding='iso-8859-1') as f:
[?2004l[?2004h>         last_lines = f.readlines()[-2:] # Get last two lines
[?2004l[?2004h>         
[?2004l[?2004h>     end_time_present = False
[?2004l[?2004h>     end_present = False
[?2004l[?2004h>     if len(last_lines) >= 1 and last_lines[-1].strip() != verification_status:
[?2004l[?2004h>         print("Error: Last line not verification status. Log might be malformed.")
[?2004l[?2004h>     elif len(last_lines) >= 1:
[?2004l[?2004h>         # Verification status is the last line. Check for END_TIME and END before it.
[?2004l[?2004h>         if len(last_lines) >= 2 and last_lines[-2].strip().startswith("END_TIME"): 
[?2004l[?2004h>             end_time_present = True
[?2004l[?2004h>         if len(last_lines) >= 3 and last_lines[-3].strip().startswith("END"):
[?2004l[?2004h>             end_present = True
[?2004l[?2004h>         
[?2004l[?2004h>     if not end_time_present:
[?2004l[?2004h>         with open(log_file_path, 'a', encoding='iso-8859-1') as f:
[?2004l[?2004h>             f.write(f"END_TIME  : {os.environ.get('START_TIME', 'UNKNOWN_START_TIME')}\n") # Use existing START_TIME if END_TIME wasn't set
[?2004l[?2004h>     if not end_present:
[?2004l[?2004h>         with open(log_file_path, 'a', encoding='iso-8859-1') as f:
[?2004l[?2004h>             f.write(f"END         : 2023-Q4 checksum verification\n")
[?2004l[?2004h> 
[?2004l[?2004h>     print(f"Verification process completed. Status appended to log: {verification_status}")
[?2004l[?2004h> 
[?2004l[?2004h> except Exception as e:
[?2004l[?2004h>     verification_status = f"VERIFICATION_FAILED - Script error: {str(e)}"
[?2004l[?2004h>     print(f"Error during verification: {str(e)}")
[?2004l[?2004h>     # Append error status
[?2004l[?2004h>     try:
[?2004l[?2004h>         with open(log_file_path, 'a', encoding='iso-8859-1') as f:
[?2004l[?2004h>             f.write(f"{verification_status}\n")
[?2004l[?2004h>     except:
[?2004l[?2004h>         pass
[?2004l[?2004h>         
[?2004l[?2004h>     print(f"Error status appended to log: {verification_status}")
[?2004l[?2004h> 
[?2004l[?2004h> EOFpython3 verify_log.py "${LOG_FILE}"
[?2004l[?2004h> rm verify_log.py