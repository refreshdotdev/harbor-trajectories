{"version": 2, "width": 160, "height": 40, "timestamp": 1771008650, "env": {"SHELL": "/bin/bash", "TERM": "screen"}}
[0.005121, "o", "\u001b[?2004hroot@b0567c87-de1e-47ba-bcd9-4add759f43c7:~# "]
[0.95693, "i", "clear\r"]
[0.95709, "o", "clear\r\n\u001b[?2004l\r"]
[0.957989, "o", "\u001b[H\u001b[J"]
[0.958172, "o", "\u001b[?2004h"]
[0.958207, "o", "root@b0567c87-de1e-47ba-bcd9-4add759f43c7:~# "]
[6.571476, "i", "cd /home/user/experiments\n"]
[6.57161, "o", "cd /home/user/experiments\r\n\u001b[?2004l\r"]
[6.571758, "o", "\u001b[?2004hroot@b0567c87-de1e-47ba-bcd9-4add759f43c7:/home/user/experiments# "]
[6.773902, "i", "ls -la\n"]
[6.774005, "o", "ls -la\r\n\u001b[?2004l\r"]
[6.775342, "o", "total 4\r\n"]
[6.775396, "o", "drwxrwxrwx 1 root root 175 Feb 12 21:48 \u001b[0m\u001b[34;42m.\u001b[0m\r\ndrwxrwxrwx 1 root root  33 Feb 12 21:48 \u001b[34;42m..\u001b[0m\r\n-rwxrwxrwx 1 root root  35 Feb 12 21:48 \u001b[01;32mexperiment_config.txt\u001b[0m\r\ndrwxrwxrwx 1 root root  28 Feb 12 21:48 \u001b[34;42mlegacy_node\u001b[0m\r\ndrwxrwxrwx 1 root root  36 Feb 12 21:48 \u001b[34;42mrun_alpha\u001b[0m\r\ndrwxrwxrwx 1 root root  36 Feb 12 21:48 \u001b[34;42mrun_beta\u001b[0m\r\ndrwxrwxrwx 1 root root   6 Feb 12 21:48 \u001b[34;42mrun_gamma\u001b[0m\r\ndrwxrwxrwx 1 root root  28 Feb 12 21:48 \u001b[34;42mrun_unstable\u001b[0m\r\ndrwxrwxrwx 1 root root  36 Feb 12 21:48 \u001b[34;42mtest_run_01\u001b[0m\r\n"]
[6.775571, "o", "\u001b[?2004h"]
[6.775589, "o", "root@b0567c87-de1e-47ba-bcd9-4add759f43c7:/home/user/experiments# "]
[11.079475, "i", "cat experiment_config.txt\n"]
[11.079592, "o", "cat experiment_config.txt\r\n\u001b[?2004l\r"]
[11.080453, "o", "exclude_regex=.*test.*\r\nprecision=3\r\n"]
[11.08062, "o", "\u001b[?2004hroot@b0567c87-de1e-47ba-bcd9-4add759f43c7:/home/user/experiments# "]
[38.780213, "i", "cat > aggregate_results.py << 'EOF'\n#!/usr/bin/env python3\nimport os\nimport re\nimport csv\nimport json\nimport glob\nimport sys\nimport hashlib\nimport datetime\nfrom typing import List, Dict, Tuple, Optional\n\nclass ExperimentAggregator:\n    def __init__(self, config_path: str):\n        self.exclude_regex = \"\"\n        self.precision = 2\n        self.valid_runs = []\n        self.min_objectives = []\n        self.latest_mtime = 0.0\n        \n        # Read and parse configuration\n        if os.path.exists(config_path):\n            with open(config_path, 'r') as f:\n                for line in f:\n                    line = line.strip()\n                    if line and not line.startswith('#'):\n                        key, value = line.split('=', 1)\n                        key = key.strip().lower()\n                        value = value.strip()\n                        if key == 'exclude_regex':\n                            self.exclude_regex = value\n                        elif key == 'precision':\n                           "]
[38.780324, "i", " try:\n                                self.precision = int(value)\n                            except ValueError:\n                                pass  # Default to 2 if invalid\n        else:\n            print(f\"Warning: Config file {config_path} not found.\")\n        \n        self.exclude_pattern = re.compile(self.exclude_regex)\n    \n    def should_exclude_dir(self, dir_name: str) -> bool:\n        return bool(self.exclude_pattern.search(dir_name))\n    \n    def parse_log_file(self, log_path: str) -> Optional[float]:\n        min_objective = None\n        encoding = 'utf-8'\n        \n        # Try UTF-8 first\n        try:\n            with open(log_path, 'r', encoding=encoding) as f:\n                reader = csv.DictReader(f)\n                for row in reader:\n                    try:\n                        obj_val = float(row.get('objective', ''))\n                        # Check for NaN, Inf, -Inf\n                        if not row.get('objective') or obj_val in [float('nan'), float('inf'), float('-inf')]:\n       "]
[38.780356, "o", "cat > aggregate_results.py << 'EOF'\r\n\u001b[?2004l\r"]
[38.780396, "i", "                     return None  # Unstable run\n                        if min_objective is None or obj_val < min_objective:\n                            min_objective = obj_val\n                    except (ValueError, TypeError):\n                        continue\n        except UnicodeDecodeError:\n            # Fallback to ISO-8859-1 (Latin-1)\n            encoding = 'iso-8859-1'\n            try:\n                with open(log_path, 'r', encoding=encoding) as f:\n                    reader = csv.DictReader(f)\n                    for row in reader:\n                        try:\n                            obj_val = float(row.get('objective', ''))\n                            if not row.get('objective') or obj_val in [float('nan'), float('inf'), float('-inf')]:\n                                return None\n                            if min_objective is None or obj_val < min_objective:\n                                min_objective = obj_val\n                        except (ValueError, TypeError):\n                       "]
[38.780427, "o", "\u001b[?2004h> "]
[38.780464, "i", "     continue\n            except Exception as e:\n                print(f\"Error reading {log_path} as {encoding}: {e}\")\n                return None\n        return min_objective\n    \n    def process_directory(self, root_dir: str):\n        for dirpath, dirnames, filenames in os.walk(root_dir):\n            # Exclude directories matching the regex pattern\n            dirnames[:] = [d for d in dirnames if not self.should_exclude_dir(d)]\n            \n            for filename in filenames:\n                if filename == 'solver_run.log':\n                    log_path = os.path.join(dirpath, filename)\n                    try:\n                        # Get file modification time\n                        mtime = os.path.getmtime(log_path)\n                        if mtime > self.latest_mtime:\n                            self.latest_mtime = mtime\n                        \n                        # Process log file\n                        min_obj = self.parse_log_file(log_path)\n                        if min_obj is not None:\n"]
[38.780493, "o", "#!/usr/bin/env python3\r\n\u001b[?2004l\r\u001b[?2004h> "]
[38.78053, "i", "                            self.min_objectives.append(min_obj)\n                            self.valid_runs.append(log_path)\n                    except Exception as e:\n                        print(f\"Error processing {log_path}: {e}\")\n    \n    def generate_summary(self, output_dir: str):\n        if not self.min_objectives:\n            print(\"No valid runs found.\")\n            return\n        \n        avg_min = sum(self.min_objectives) / len(self.min_objectives)\n        rounded_avg = round(avg_min, self.precision)\n        \n        # Convert latest_mtime to ISO format\n        try:\n            latest_activity = datetime.datetime.fromtimestamp(self.latest_mtime).isoformat()\n        except Exception:\n            latest_activity = \"1970-01-01T00:00:00\"\n        \n        summary_data = {\n            \"valid_runs\": len(self.min_objectives),\n            \"average_min_objective\": rounded_avg,\n            \"latest_activity\": latest_activity\n        }\n        \n        # Write summary.json in ASCII\n        with open(os.path.jo"]
[38.780566, "o", "import os\r\n\u001b[?2004l\r\u001b[?2004h> "]
[38.780602, "i", "in(output_dir, 'summary.json'), 'w', encoding='ascii') as f:\n            json.dump(summary_data, f, ensure_ascii=True)\n        \n        # Generate manifest\n        with open(os.path.join(output_dir, 'summary.json'), 'rb') as f:\n            md5 = hashlib.md5(f.read()).hexdigest()\n        manifest_str = f\"summary.json:{md5}\"\n        \n        with open(os.path.join(output_dir, 'manifest.txt'), 'w') as f:\n            f.write(manifest_str)\n            # Ensure no trailing newline\n            f.seek(0, os.SEEK_END)\n            f.truncate()\n\nif __name__ == '__main__':\n    aggregator = ExperimentAggregator('experiment_config.txt')\n    aggregator.process_directory('.')  # Current directory\n    aggregator.generate_summary('.')   # Output files in current directory\nEOF"]
[38.780634, "o", "import re\r\n\u001b[?2004l\r\u001b[?2004h> import csv\r\n"]
[38.780679, "o", "\u001b[?2004l\r\u001b[?2004h> "]
[38.780728, "o", "import json\r\n\u001b[?2004l\r\u001b[?2004h"]
[38.780762, "o", "> "]
[38.780802, "o", "import glob\r\n\u001b[?2004l\r"]
[38.780829, "o", "\u001b[?2004h> "]
[38.780854, "o", "import sys\r\n\u001b[?2004l\r"]
[38.780888, "o", "\u001b[?2004h> "]
[38.78095, "o", "import hashlib\r\n\u001b[?2004l\r"]
[38.780975, "o", "\u001b[?2004h> "]
[38.781031, "o", "import datetime\r\n\u001b[?2004l\r\u001b[?2004h> "]
[38.781226, "o", "from typing import List, Dict, Tuple, Optional\r\n\u001b[?2004l\r\u001b[?2004h"]
[38.781256, "o", "> \r\n\u001b[?2004l\r\u001b[?2004h"]
[38.781292, "o", "> "]
[38.781377, "o", "class ExperimentAggregator:\r\n\u001b[?2004l\r"]
[38.781407, "o", "\u001b[?2004h> "]
[38.781552, "o", "    def __init__(self, config_path: str):\r\n\u001b[?2004l\r"]
[38.78159, "o", "\u001b[?2004h> "]
[38.781719, "o", "        self.exclude_regex = \"\"\r\n\u001b[?2004l\r"]
[38.781749, "o", "\u001b[?2004h> "]
[38.78183, "o", "        self.precision = 2\r\n\u001b[?2004l\r"]
[38.78186, "o", "\u001b[?2004h> "]
[38.781949, "o", "        self.valid_runs = []\r\n\u001b[?2004l\r"]
[38.781987, "o", "\u001b[?2004h> "]
[38.782074, "o", "        self.min_objectives = []\r\n\u001b[?2004l\r\u001b[?2004h"]
[38.782107, "o", "> "]
[38.782199, "o", "        self.latest_mtime = 0.0\r\n\u001b[?2004l\r\u001b[?2004h"]
[38.782236, "o", ">         \r\n\u001b[?2004l\r"]
[38.782269, "o", "\u001b[?2004h> "]
[38.782364, "o", "        # Read and parse configuration\r\n\u001b[?2004l\r"]
[38.782395, "o", "\u001b[?2004h> "]
[38.782545, "o", "        if os.path.exists(config_path):\r\n\u001b[?2004l\r"]
[38.782573, "o", "\u001b[?2004h> "]
[38.782763, "o", "            with open(config_path, 'r') as f:\r\n\u001b[?2004l\r"]
[38.782792, "o", "\u001b[?2004h> "]
[38.782882, "o", "                for line in f:\r\n\u001b[?2004l\r"]
[38.782912, "o", "\u001b[?2004h> "]
[38.783027, "o", "                    line = line.strip()\r\n\u001b[?2004l\r"]
[38.783056, "o", "\u001b[?2004h> "]
[38.78328, "o", "                    if line and not line.startswith('#'):\r\n\u001b[?2004l\r"]
[38.783314, "o", "\u001b[?2004h> "]
[38.783506, "o", "                        key, value = line.split('=', 1)\r\n\u001b[?2004l\r"]
[38.783537, "o", "\u001b[?2004h> "]
[38.783684, "o", "                        key = key.strip().lower()\r\n\u001b[?2004l\r"]
[38.78371, "o", "\u001b[?2004h> "]
[38.783846, "o", "                        value = value.strip()\r\n\u001b[?2004l\r"]
[38.783877, "o", "\u001b[?2004h> "]
[38.784017, "o", "                        if key == 'exclude_regex':\r\n\u001b[?2004l\r"]
[38.784047, "o", "\u001b[?2004h> "]
[38.784193, "o", "                            self.exclude_regex = value\r\n\u001b[?2004l\r"]
[38.784223, "o", "\u001b[?2004h> "]
[38.784357, "o", "                        elif key == 'precision':\r\n\u001b[?2004l\r"]
[38.784388, "o", "\u001b[?2004h> "]
[38.784471, "o", "                            try:\r\n\u001b[?2004l\r"]
[38.7845, "o", "\u001b[?2004h> "]
[38.78467, "o", "                                self.precision = int(value)\r\n\u001b[?2004l\r"]
[38.7847, "o", "\u001b[?2004h> "]
[38.784834, "o", "                            except ValueError:\r\n\u001b[?2004l\r\u001b[?2004h"]
[38.784864, "o", "> "]
[38.785033, "o", "                                pass  # Default to 2 if invalid\r\n\u001b[?2004l\r"]
[38.785063, "o", "\u001b[?2004h> "]
[38.785098, "o", "        else:\r\n\u001b[?2004l\r"]
[38.785125, "o", "\u001b[?2004h> "]
[38.785315, "o", "            print(f\"Warning: Config file {config_path} not found.\")\r\n\u001b[?2004l\r"]
[38.785354, "o", "\u001b[?2004h> "]
[38.785379, "o", "        \r\n\u001b[?2004l\r\u001b[?2004h> "]
[38.785632, "o", "        self.exclude_pattern = re.compile(self.exclude_regex)\r\n\u001b[?2004l\r"]
[38.785667, "o", "\u001b[?2004h> "]
[38.785715, "o", "    \r\n\u001b[?2004l\r\u001b[?2004h> "]
[38.785863, "o", "    def should_exclude_dir(self, dir_name: str) -> bool:\r\n\u001b[?2004l\r"]
[38.785902, "o", "\u001b[?2004h> "]
[38.786074, "o", "        return bool(self.exclude_pattern.search(dir_name))\r\n\u001b[?2004l\r"]
[38.786115, "o", "\u001b[?2004h>     \r\n\u001b[?2004l\r\u001b[?2004h"]
[38.786159, "o", "> "]
[38.786324, "o", "    def parse_log_file(self, log_path: str) -> Optional[float]:\r\n\u001b[?2004l\r"]
[38.786355, "o", "\u001b[?2004h> "]
[38.786427, "o", "        min_objective = None\r\n\u001b[?2004l\r"]
[38.786464, "o", "\u001b[?2004h> "]
[38.786526, "o", "        encoding = 'utf-8'\r\n\u001b[?2004l\r"]
[38.786559, "o", "\u001b[?2004h> "]
[38.786587, "o", "        \r\n\u001b[?2004l\r\u001b[?2004h> "]
[38.786674, "o", "        # Try UTF-8 first"]
[38.786706, "o", "\r\n\u001b[?2004l\r\u001b[?2004h"]
[38.786741, "o", "> "]
[38.786775, "o", "        try:\r\n\u001b[?2004l\r\u001b[?2004h> "]
[38.786959, "o", "            with open(log_path, 'r', encoding=encoding) as f:\r\n\u001b[?2004l\r"]
[38.786991, "o", "\u001b[?2004h> "]
[38.787103, "o", "                reader = csv.DictReader(f)\r\n\u001b[?2004l\r"]
[38.787133, "o", "\u001b[?2004h> "]
[38.787223, "o", "                for row in reader:\r\n\u001b[?2004l\r"]
[38.787248, "o", "\u001b[?2004h> "]
[38.787318, "o", "                    try:\r\n\u001b[?2004l\r"]
[38.787347, "o", "\u001b[?2004h> "]
[38.787494, "o", "                        obj_val = float(row.get('objective', ''))\r\n\u001b[?2004l\r"]
[38.787523, "o", "\u001b[?2004h> "]
[38.787635, "o", "                        # Check for NaN, Inf, -Inf\r\n\u001b[?2004l\r"]
[38.78767, "o", "\u001b[?2004h> "]
[38.787922, "o", "                        if not row.get('objective') or obj_val in [float('nan'), float('inf'), float('-inf')]:\r\n\u001b[?2004l\r"]
[38.787953, "o", "\u001b[?2004h> "]
[38.788074, "o", "                            return None  # Unstable run\r\n\u001b[?2004l\r"]
[38.788104, "o", "\u001b[?2004h> "]
[38.78828, "o", "                        if min_objective is None or obj_val < min_objective:\r\n\u001b[?2004l\r"]
[38.788309, "o", "\u001b[?2004h> "]
[38.788424, "o", "                            min_objective = obj_val\r\n\u001b[?2004l\r"]
[38.788453, "o", "\u001b[?2004h> "]
[38.788567, "o", "                    except (ValueError, TypeError):\r\n\u001b[?2004l\r"]
[38.788596, "o", "\u001b[?2004h> "]
[38.788677, "o", "                        continue\r\n\u001b[?2004l\r\u001b[?2004h"]
[38.788707, "o", "> "]
[38.788775, "o", "        except UnicodeDecodeError:\r\n\u001b[?2004l\r"]
[38.788805, "o", "\u001b[?2004h> "]
[38.788907, "o", "            # Fallback to ISO-8859-1 (Latin-1)\r\n\u001b[?2004l\r"]
[38.788936, "o", "\u001b[?2004h> "]
[38.789019, "o", "            encoding = 'iso-8859-1'\r\n\u001b[?2004l\r"]
[38.789048, "o", "\u001b[?2004h> "]
[38.789084, "o", "            try:\r\n\u001b[?2004l\r"]
[38.789104, "o", "\u001b[?2004h> "]
[38.789253, "o", "                with open(log_path, 'r', encoding=encoding) as f:\r\n\u001b[?2004l\r"]
[38.789283, "o", "\u001b[?2004h> "]
[38.789385, "o", "                    reader = csv.DictReader(f)\r\n\u001b[?2004l\r"]
[38.789414, "o", "\u001b[?2004h> "]
[38.789497, "o", "                    for row in reader:\r\n\u001b[?2004l\r"]
[38.789526, "o", "\u001b[?2004h> "]
[38.789588, "o", "                        try:\r\n\u001b[?2004l\r"]
[38.789616, "o", "\u001b[?2004h> "]
[38.78978, "o", "                            obj_val = float(row.get('objective', ''))\r\n\u001b[?2004l\r"]
[38.789811, "o", "\u001b[?2004h> "]
[38.790069, "o", "                            if not row.get('objective') or obj_val in [float('nan'), float('inf'), float('-inf')]:\r\n\u001b[?2004l\r"]
[38.790099, "o", "\u001b[?2004h> "]
[38.790199, "o", "                                return None\r\n\u001b[?2004l\r"]
[38.790228, "o", "\u001b[?2004h> "]
[38.790409, "o", "                            if min_objective is None or obj_val < min_objective:\r\n\u001b[?2004l\r"]
[38.790438, "o", "\u001b[?2004h> "]
[38.790561, "o", "                                min_objective = obj_val\r\n\u001b[?2004l\r"]
[38.79059, "o", "\u001b[?2004h> "]
[38.790722, "o", "                        except (ValueError, TypeError):\r\n\u001b[?2004l\r"]
[38.790752, "o", "\u001b[?2004h> "]
[38.790829, "o", "                            continue\r\n\u001b[?2004l\r"]
[38.790858, "o", "\u001b[?2004h> "]
[38.790932, "o", "            except Exception as e:\r\n\u001b[?2004l\r"]
[38.790961, "o", "\u001b[?2004h> "]
[38.791122, "o", "                print(f\"Error reading {log_path} as {encoding}: {e}\")\r\n\u001b[?2004l\r"]
[38.791151, "o", "\u001b[?2004h> "]
[38.791209, "o", "                return None\r\n\u001b[?2004l\r"]
[38.791238, "o", "\u001b[?2004h> "]
[38.7913, "o", "        return min_objective\r\n\u001b[?2004l\r"]
[38.791328, "o", "\u001b[?2004h>     \r\n\u001b[?2004l\r"]
[38.79135, "o", "\u001b[?2004h> "]
[38.791467, "o", "    def process_directory(self, root_dir: str):\r\n\u001b[?2004l\r"]
[38.791496, "o", "\u001b[?2004h> "]
[38.791636, "o", "        for dirpath, dirnames, filenames in os.walk(root_dir):\r\n\u001b[?2004l\r"]
[38.791669, "o", "\u001b[?2004h> "]
[38.791808, "o", "            # Exclude directories matching the regex pattern\r\n\u001b[?2004l\r"]
[38.791839, "o", "\u001b[?2004h> "]
[38.792019, "o", "            dirnames[:] = [d for d in dirnames if not self.should_exclude_dir(d)]\r\n\u001b[?2004l\r"]
[38.792048, "o", "\u001b[?2004h> "]
[38.792072, "o", "            \r\n\u001b[?2004l\r"]
[38.792094, "o", "\u001b[?2004h> "]
[38.79219, "o", "            for filename in filenames:\r\n\u001b[?2004l\r"]
[38.79222, "o", "\u001b[?2004h> "]
[38.792326, "o", "                if filename == 'solver_run.log':\r\n\u001b[?2004l\r"]
[38.792355, "o", "\u001b[?2004h> "]
[38.792501, "o", "                    log_path = os.path.join(dirpath, filename)\r\n\u001b[?2004l\r\u001b[?2004h"]
[38.792532, "o", "> "]
[38.792578, "o", "                    try:\r\n\u001b[?2004l\r\u001b[?2004h"]
[38.792609, "o", "> "]
[38.792727, "o", "                        # Get file modification time\r\n\u001b[?2004l\r"]
[38.792758, "o", "\u001b[?2004h> "]
[38.792881, "o", "                        mtime = os.path.getmtime(log_path)\r\n\u001b[?2004l\r"]
[38.79291, "o", "\u001b[?2004h> "]
[38.793029, "o", "                        if mtime > self.latest_mtime:\r\n\u001b[?2004l\r"]
[38.793058, "o", "\u001b[?2004h> "]
[38.79318, "o", "                            self.latest_mtime = mtime\r\n\u001b[?2004l\r"]
[38.79321, "o", "\u001b[?2004h> "]
[38.793263, "o", "                        \r\n\u001b[?2004l\r"]
[38.793292, "o", "\u001b[?2004h> "]
[38.793383, "o", "                        # Process log file\r\n\u001b[?2004l\r"]
[38.793411, "o", "\u001b[?2004h> "]
[38.793551, "o", "                        min_obj = self.parse_log_file(log_path)\r\n\u001b[?2004l\r"]
[38.79358, "o", "\u001b[?2004h> "]
[38.793695, "o", "                        if min_obj is not None:\r\n\u001b[?2004l\r"]
[38.793733, "o", "\u001b[?2004h> "]
[38.793859, "o", "                            self.min_objectives.append(min_obj)\r\n\u001b[?2004l\r"]
[38.79389, "o", "\u001b[?2004h> "]
[38.794023, "o", "                            self.valid_runs.append(log_path)\r\n\u001b[?2004l\r"]
[38.794053, "o", "\u001b[?2004h> "]
[38.794155, "o", "                    except Exception as e:\r\n\u001b[?2004l\r"]
[38.794184, "o", "\u001b[?2004h> "]
[38.794337, "o", "                        print(f\"Error processing {log_path}: {e}\")\r\n\u001b[?2004l\r"]
[38.794367, "o", "\u001b[?2004h>     \r\n\u001b[?2004l\r"]
[38.794389, "o", "\u001b[?2004h> "]
[38.794505, "o", "    def generate_summary(self, output_dir: str):\r\n\u001b[?2004l\r"]
[38.794535, "o", "\u001b[?2004h> "]
[38.794612, "o", "        if not self.min_objectives:\r\n\u001b[?2004l\r"]
[38.794641, "o", "\u001b[?2004h> "]
[38.794739, "o", "            print(\"No valid runs found.\")\r\n\u001b[?2004l\r"]
[38.794768, "o", "\u001b[?2004h> "]
[38.794809, "o", "            return\r\n\u001b[?2004l\r"]
[38.794832, "o", "\u001b[?2004h> "]
[38.794856, "o", "        \r\n\u001b[?2004l\r\u001b[?2004h"]
[38.794879, "o", "> "]
[38.795032, "o", "        avg_min = sum(self.min_objectives) / len(self.min_objectives)\r\n\u001b[?2004l\r"]
[38.795062, "o", "\u001b[?2004h> "]
[38.795178, "o", "        rounded_avg = round(avg_min, self.precision)\r\n\u001b[?2004l\r"]
[38.795208, "o", "\u001b[?2004h> "]
[38.795243, "o", "        \r\n\u001b[?2004l\r\u001b[?2004h"]
[38.795265, "o", "> "]
[38.79539, "o", "        # Convert latest_mtime to ISO format\r\n\u001b[?2004l\r"]
[38.79542, "o", "\u001b[?2004h> "]
[38.795445, "o", "        try:\r\n\u001b[?2004l\r\u001b[?2004h"]
[38.795468, "o", "> "]
[38.795798, "o", "            latest_activity = datetime.datetime.fromtimestamp(self.latest_mtime).isoformat()\r\n\u001b[?2004l\r\u001b[?2004h> "]
[38.795888, "o", "        except Exception:\r\n\u001b[?2004l\r"]
[38.795918, "o", "\u001b[?2004h> "]
[38.796061, "o", "            latest_activity = \"1970-01-01T00:00:00\"\r\n\u001b[?2004l\r"]
[38.79609, "o", "\u001b[?2004h> "]
[38.796117, "o", "        \r\n\u001b[?2004l\r"]
[38.796147, "o", "\u001b[?2004h> "]
[38.796218, "o", "        summary_data = {\r\n\u001b[?2004l\r"]
[38.796255, "o", "\u001b[?2004h> "]
[38.7964, "o", "            \"valid_runs\": len(self.min_objectives),\r\n\u001b[?2004l\r"]
[38.796427, "o", "\u001b[?2004h> "]
[38.796577, "o", "            \"average_min_objective\": rounded_avg,\r\n\u001b[?2004l\r"]
[38.796608, "o", "\u001b[?2004h> "]
[38.796752, "o", "            \"latest_activity\": latest_activity\r\n\u001b[?2004l\r"]
[38.796778, "o", "\u001b[?2004h> "]
[38.796803, "o", "        }\r\n\u001b[?2004l\r"]
[38.796828, "o", "\u001b[?2004h> "]
[38.796865, "o", "        \r\n\u001b[?2004l\r"]
[38.79689, "o", "\u001b[?2004h> "]
[38.796996, "o", "        # Write summary.json in ASCII\r\n\u001b[?2004l\r"]
[38.79702, "o", "\u001b[?2004h> "]
[38.797221, "o", "        with open(os.path.join(output_dir, 'summary.json'), 'w', encoding='ascii') as f:\r\n\u001b[?2004l\r"]
[38.797246, "o", "\u001b[?2004h> "]
[38.797377, "o", "            json.dump(summary_data, f, ensure_ascii=True)\r\n\u001b[?2004l\r"]
[38.797401, "o", "\u001b[?2004h> "]
[38.797427, "o", "        \r\n\u001b[?2004l\r\u001b[?2004h"]
[38.797453, "o", "> "]
[38.797506, "o", "        # Generate manifest\r\n\u001b[?2004l\r"]
[38.79753, "o", "\u001b[?2004h> "]
[38.797707, "o", "        with open(os.path.join(output_dir, 'summary.json'), 'rb') as f:\r\n\u001b[?2004l\r"]
[38.79776, "o", "\u001b[?2004h> "]
[38.797847, "o", "            md5 = hashlib.md5(f.read()).hexdigest()\r\n\u001b[?2004l\r\u001b[?2004h"]
[38.797879, "o", "> "]
[38.797968, "o", "        manifest_str = f\"summary.json:{md5}\"\r\n\u001b[?2004l\r"]
[38.797993, "o", "\u001b[?2004h> "]
[38.798018, "o", "        \r\n\u001b[?2004l\r\u001b[?2004h"]
[38.798042, "o", "> "]
[38.798196, "o", "        with open(os.path.join(output_dir, 'manifest.txt'), 'w') as f:\r\n\u001b[?2004l\r"]
[38.798221, "o", "\u001b[?2004h> "]
[38.798295, "o", "            f.write(manifest_str)\r\n\u001b[?2004l\r"]
[38.798319, "o", "\u001b[?2004h> "]
[38.798411, "o", "            # Ensure no trailing newline\r\n\u001b[?2004l\r"]
[38.798435, "o", "\u001b[?2004h> "]
[38.798518, "o", "            f.seek(0, os.SEEK_END)\r\n\u001b[?2004l\r"]
[38.798542, "o", "\u001b[?2004h> "]
[38.798597, "o", "            f.truncate()\r\n\u001b[?2004l\r"]
[38.798622, "o", "\u001b[?2004h> \r\n\u001b[?2004l\r"]
[38.798646, "o", "\u001b[?2004h> "]
[38.798711, "o", "if __name__ == '__main__':\r\n\u001b[?2004l\r"]
[38.798737, "o", "\u001b[?2004h> "]
[38.79888, "o", "    aggregator = ExperimentAggregator('experiment_config.txt')\r\n\u001b[?2004l\r"]
[38.798906, "o", "\u001b[?2004h> "]
[38.799041, "o", "    aggregator.process_directory('.')  # Current directory\r\n\u001b[?2004l\r"]
[38.799065, "o", "\u001b[?2004h> "]
[38.799248, "o", "    aggregator.generate_summary('.')   # Output files in current directory\r\n\u001b[?2004l\r\u001b[?2004h"]
[38.799284, "o", "> EOF"]
[39.385475, "i", "python3 aggregate_results.py\n"]
[39.3856, "o", "python3 aggregate_results.py\r\n\u001b[?2004l\r"]
[39.385637, "o", "\u001b[?2004h> "]
[47.497481, "i", "ls -la summary.json manifest.txt\n"]
[47.49774, "o", "ls -la summary.json manifest.txt\r\n"]
[47.497923, "o", "\u001b[?2004l\r\u001b[?2004h> "]
[47.606937, "i", "cat summary.json\n"]
[47.607071, "o", "cat summary.json\r\n"]
[47.607104, "o", "\u001b[?2004l\r"]
[47.607131, "o", "\u001b[?2004h"]
[47.607168, "o", "> "]
[47.773808, "i", "file summary.json\n"]
[47.773971, "o", "file summary.json\r\n\u001b[?2004l\r"]
[47.774048, "o", "\u001b[?2004h"]
[47.77411, "o", "> "]
[48.063012, "i", "cat manifest.txt\n"]
[48.063178, "o", "cat manifest.txt\r\n\u001b[?2004l\r\u001b[?2004h> "]
[48.213355, "i", "wc -c manifest.txt\n"]
[48.213571, "o", "wc -c manifest.txt\r\n\u001b[?2004l\r"]
[48.213642, "o", "\u001b[?2004h"]
[48.213715, "o", "> "]
[66.85387, "i", "ls\n"]
[66.853969, "o", "ls\r\n\u001b[?2004l\r"]
[66.85401, "o", "\u001b[?2004h"]
[66.854031, "o", "> "]
[70.993019, "i", "pwd\n"]
[70.993154, "o", "pwd\r\n\u001b[?2004l\r\u001b[?2004h> "]
[71.128549, "i", "ls -la\n"]
[71.128721, "o", "ls -la\r\n\u001b[?2004l\r"]
[71.128744, "o", "\u001b[?2004h> "]
[74.882915, "i", "echo \"test\"\n"]
[74.883045, "o", "echo \"test\"\r\n\u001b[?2004l\r"]
[74.883114, "o", "\u001b[?2004h> "]
[79.087428, "i", "ls /home/user/experiments/\n"]
[79.087538, "o", "ls /home/user/experiments/\r\n\u001b[?2004l\r"]
[79.087566, "o", "\u001b[?2004h> "]
[84.476859, "i", "find . -name 'summary.json' -o -name 'manifest.txt'"]
[84.477046, "o", "find . -name 'summary.json' -o -name 'manifest.txt'"]
[89.002715, "i", "ls aggregate_results.py\n"]
[89.002966, "o", "ls aggregate_results.py\r\n\u001b[?2004l\r"]
[89.003036, "o", "\u001b[?2004h"]
[89.003078, "o", "> "]
[89.101814, "i", "python3 aggregate_results.py\n"]
[89.102038, "o", "python3 aggregate_results.py\r\n\u001b[?2004l\r"]
[89.102091, "o", "\u001b[?2004h> "]
[94.505283, "i", "whoami\n"]
[94.505396, "o", "whoami\r\n\u001b[?2004l\r\u001b[?2004h> "]
