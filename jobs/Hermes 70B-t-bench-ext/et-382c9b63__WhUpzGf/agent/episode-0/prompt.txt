You are an AI assistant tasked with solving command-line tasks in a Linux environment. You will be given a task description and the output from previously executed commands. Your goal is to solve the task by providing batches of shell commands.

Format your response as JSON with the following structure:

{
  "analysis": "Analyze the current state based on the terminal output provided. What do you see? What has been accomplished? What still needs to be done?",
  "plan": "Describe your plan for the next steps. What commands will you run and why? Be specific about what you expect each command to accomplish.",
  "commands": [
    {
      "keystrokes": "ls -la\n",
      "duration": 0.1
    },
    {
      "keystrokes": "cd project\n",
      "duration": 0.1
    }
  ],
  "task_complete": true
}

Required fields:
- "analysis": Your analysis of the current situation
- "plan": Your plan for the next steps
- "commands": Array of command objects to execute

Optional fields:
- "task_complete": Boolean indicating if the task is complete (defaults to false if not present)

Command object structure:
- "keystrokes": String containing the exact keystrokes to send to the terminal (required)
- "duration": Number of seconds to wait for the command to complete before the next command will be executed (defaults to 1.0 if not present)

IMPORTANT: The text inside "keystrokes" will be used completely verbatim as keystrokes. Write commands exactly as you want them sent to the terminal:
- You must end every command with a newline (\n) or it will not execute.
- For special key sequences, use tmux-style escape sequences:
  - C-c for Ctrl+C
  - C-d for Ctrl+D

The "duration" attribute specifies the number of seconds to wait for the command to complete (default: 1.0) before the next command will be executed. On immediate tasks (e.g., cd, ls, echo, cat) set a duration of 0.1 seconds. On commands (e.g., gcc, find, rustc) set a duration of 1.0 seconds. On slow commands (e.g., make, python3 [long running script], wget [file]) set an appropriate duration as you determine necessary.

It is better to set a smaller duration than a longer duration. It is always possible to wait again if the prior output has not finished, by running {"keystrokes": "", "duration": 10.0} on subsequent requests to wait longer. Never wait longer than 60 seconds; prefer to poll to see intermediate result status.

Important notes:
- Each command's keystrokes are sent exactly as written to the terminal
- Do not include extra whitespace before or after the keystrokes unless it's part of the intended command
- Extra text before or after the JSON will generate warnings but be tolerated
- The JSON must be valid - use proper escaping for quotes and special characters within strings
- Commands array can be empty if you want to wait without taking action

Task Description:
# Advanced Nmap Log Parsing & Benchmark Task

You are a DevSecOps engineer responsible for integrating raw Nmap scan data into the corporate "CYBER-CORE" mainframe. The scans were executed by various regional teams and dumped onto a shared filesystem. Your task is to normalize this data, validate it, and produce two specific artifacts for ingestion.

## Input Data

The raw log files are located in `/home/user/scan_logs`.

*   **Discovery**: You must process `.log` files found in `/home/user/scan_logs` AND `/home/user/scan_logs/archive`.
*   **Exclusion**: You must explicitly IGNORE any files found in directories named `backup`, regardless of their extension. You must also ignore any file that is not a `.log` file.
*   **Date Filtering**: The CYBER-CORE system is currently processing the "May 2023" batch. You must parse the header of each log file (e.g., `Starting Nmap ... at YYYY-MM-DD...`) and **discard** any logs that were not executed in **May 2023**.
*   **Encoding Warning**: Some logs were generated by legacy machines in regional offices (e.g., Munich) and may be encoded in **ISO-8859-1 (Latin-1)**. These files may contain non-ASCII characters in the service banners. You must detect or handle this to ensure the final output is clean Unicode.

## Requirements

You must generate two output files in `/home/user/ingest/`. Create this directory if it does not exist.

### Artifact 1: The Manifest (`manifest.json`)

Before generating the CSV, you must create a JSON manifest listing every valid log file you intend to process.
*   Path: `/home/user/ingest/manifest.json`
*   Format: A JSON object with a single key `"scans"`, which is an array of objects.
*   Each object must have:
    *   `"filename"`: The name of the file (e.g., `scan1.log`).
    *   `"sha256"`: The SHA256 checksum of the original raw file.
*   The JSON must be valid, standard UTF-8.

### Artifact 2: The Benchmark CSV (`cyber_core_import.csv`)

This file aggregates the scan metrics.
*   Path: `/home/user/ingest/cyber_core_import.csv`
*   **Critical Encoding Requirement**: The mainframe requires this file to be encoded in **UTF-16 Little Endian (UTF-16LE)** with a **Byte Order Mark (BOM)**. Failure to strictly adhere to this encoding will cause the ingestion job to fail.
*   **Column Format**: The CSV must have exactly these headers:
    `Hash,Host,Open_Ports,Duration,PPS`

    *   **Hash**: The first 8 characters of the file's SHA256 checksum.
    *   **Host**: The IP address scanned.
    *   **Open_Ports**: A comma-separated list of open TCP ports, **sorted numerically**. This field must ALWAYS be double-quoted (e.g., `"22,80"`). If no ports are open, use `""`.
    *   **Duration**: The "real" time from the `#METRIC` line.
    *   **PPS**: Ports Per Second, calculated as `(count of open ports) / (duration)`. Round to **2 decimal places**. If duration is 0 (unlikely) or no ports are open, PPS is `0.00`.

*   **Sorting Logic**:
    The order of rows in the CSV is critical for index optimization:
    1.  **Priority 1 (Critical Gateways)**: Any host that has **BOTH** port 80 and port 443 open is considered a Critical Gateway. These rows must appear **first** in the file.
    2.  **Priority 2 (Standard Hosts)**: All other hosts appear after the gateways.
    3.  **Tie-Breaker**: Within each priority group, sort by **IP Address** in ascending numeric order (e.g., `10.0.0.5` comes before `10.0.0.20`).

### Artifact 3: Performance Self-Check

*   Append a final comment line to the **end** of the CSV file (after all data).
*   Format: `#parser_runtime=<FLOAT>` (seconds with millisecond precision).
*   **Note**: This comment line must also be encoded in UTF-16LE to match the rest of the file.

## Constraints

*   Use standard utilities available in a minimal environment (Python3, Bash, GNU coreutils, awk, sed, grep, iconv).
*   Do not install new packages.
*   Display the content of `manifest.json` to the console at the end.
*   Do NOT display the CSV to the console (binary data may corrupt the terminal).

Current terminal state:
Current Terminal Screen:
root@d311dcd6-b0da-41ad-83e2-23023af13f30:~#








































