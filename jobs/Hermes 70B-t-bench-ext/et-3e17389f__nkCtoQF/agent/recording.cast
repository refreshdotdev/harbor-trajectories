{"version": 2, "width": 160, "height": 40, "timestamp": 1771009541, "env": {"SHELL": "/bin/bash", "TERM": "screen"}}
[0.006021, "o", "\u001b[?2004hroot@b82784c7-2a45-4d16-9e1a-4e0b54903093:~# "]
[0.976311, "i", "clear\r"]
[0.976451, "o", "clear\r\n\u001b[?2004l\r"]
[0.977741, "o", "\u001b[H\u001b[J"]
[0.977912, "o", "\u001b[?2004hroot@b82784c7-2a45-4d16-9e1a-4e0b54903093:~# "]
[8.174126, "i", "useradd -m -s /bin/bash user\n"]
[8.174489, "o", "useradd -m -s /bin/bash user\r\n\u001b[?2004l\r"]
[8.175058, "o", "bash: useradd: command not found\r\n"]
[8.17535, "o", "\u001b[?2004h"]
[8.175422, "o", "root@b82784c7-2a45-4d16-9e1a-4e0b54903093:~# "]
[9.107334, "i", "su - user\n"]
[9.10752, "o", "su - user\r\n\u001b[?2004l\r"]
[9.109894, "o", "su: user user does not exist or the user entry does not contain all the required fields\r\n"]
[9.110182, "o", "\u001b[?2004h"]
[9.110213, "o", "root@b82784c7-2a45-4d16-9e1a-4e0b54903093:~# "]
[21.220926, "i", "mkdir -p /home/user/.venvs\n"]
[21.221055, "o", "mkdir -p /home/user/.venvs\r\n\u001b[?2004l\r"]
[21.223072, "o", "\u001b[?2004hroot@b82784c7-2a45-4d16-9e1a-4e0b54903093:~# "]
[21.293625, "i", "mkdir -p /home/user/db_queries\n"]
[21.293769, "o", "mkdir -p /home/user/db_queries\r\n\u001b[?2004l\r"]
[21.294938, "o", "\u001b[?2004hroot@b82784c7-2a45-4d16-9e1a-4e0b54903093:~# "]
[33.506866, "i", "cd /home/user/.venvs\n"]
[33.507086, "o", "cd /home/user/.venvs\r\n\u001b[?2004l\r"]
[33.507244, "o", "\u001b[?2004hroot@b82784c7-2a45-4d16-9e1a-4e0b54903093:/home/user/.venvs# "]
[33.587172, "i", "python3 --version\n"]
[33.587445, "o", "python3 --version\r\n\u001b[?2004l\r"]
[33.589132, "o", "Python 3.10.12\r\n"]
[33.589458, "o", "\u001b[?2004h"]
[33.589505, "o", "root@b82784c7-2a45-4d16-9e1a-4e0b54903093:/home/user/.venvs# "]
[33.677572, "i", "python3 -m venv opt_queries\n"]
[33.677757, "o", "python3 -m venv opt_queries\r\n\u001b[?2004l\r"]
[34.682615, "i", "ls -la\n"]
[34.682724, "o", "ls -la\r\n"]
[35.763246, "o", "\u001b[?2004hroot@b82784c7-2a45-4d16-9e1a-4e0b54903093:/home/user/.venvs# "]
[35.763377, "o", "ls -la\r\n\u001b[?2004l\r"]
[35.76488, "o", "total 0\r\n"]
[35.764936, "o", "drwxr-xr-x 3 root root 33 Feb 13 19:06 \u001b[0m\u001b[01;34m.\u001b[0m\r\ndrwxr-xr-x 1 root root 28 Feb 13 19:06 \u001b[01;34m..\u001b[0m\r\ndrwxr-xr-x 5 root root 98 Feb 13 19:06 \u001b[01;34mopt_queries\u001b[0m\r\n"]
[35.765155, "o", "\u001b[?2004h"]
[35.765186, "o", "root@b82784c7-2a45-4d16-9e1a-4e0b54903093:/home/user/.venvs# "]
[45.271094, "i", "source opt_queries/bin/activate\n"]
[45.271221, "o", "source opt_queries/bin/activate\r\n\u001b[?2004l\r"]
[45.271535, "o", "\u001b[?2004h"]
[45.271586, "o", "(opt_queries) root@b82784c7-2a45-4d16-9e1a-4e0b54903093:/home/user/.venvs# "]
[45.412219, "i", "pip install sqlparse==0.4.4\n"]
[45.412339, "o", "pip install sqlparse==0.4.4\r\n"]
[45.412368, "o", "\u001b[?2004l\r"]
[45.721329, "o", "Collecting sqlparse==0.4.4\r\n"]
[45.756618, "o", "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\r\n"]
[45.756883, "o", "\u001b[?25l"]
[45.757884, "o", "     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.2 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"]
[45.766631, "o", "\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n\u001b[?25h"]
[45.785705, "o", "Installing collected packages: sqlparse\r\n"]
[45.809156, "o", "Successfully installed sqlparse-0.4.4\r\n"]
[45.846539, "o", "\u001b[?2004h(opt_queries) root@b82784c7-2a45-4d16-9e1a-4e0b54903093:/home/user/.venvs# "]
[46.482543, "i", "pip freeze\n"]
[46.482713, "o", "pip freeze\r\n\u001b[?2004l\r"]
[46.704136, "o", "sqlparse==0.4.4\r\n"]
[46.732434, "o", "\u001b[?2004h(opt_queries) root@b82784c7-2a45-4d16-9e1a-4e0b54903093:/home/user/.venvs# "]
[46.960691, "i", "echo \"sqlparse==0.4.4\" > opt_queries/requirements.txt\n"]
[46.961027, "o", "echo \"sqlparse==0.4.4\" > opt_queries/requirements.txt\r\n\u001b[?2004l\r"]
[46.961262, "o", "\u001b[?2004h(opt_queries) root@b82784c7-2a45-4d16-9e1a-4e0b54903093:/home/user/.venvs# "]
[86.726726, "i", "cd /home/user/db_queries\n"]
[86.726887, "o", "cd /home/user/db_queries\r\n\u001b[?2004l\r"]
[86.726942, "o", "\u001b[?2004h"]
[86.726957, "o", "(opt_queries) root@b82784c7-2a45-4d16-9e1a-4e0b54903093:/home/user/db_queries# "]
[86.864324, "i", "cat > process_batch.py << 'EOF'\n#!/usr/bin/env python3\n\nimport os\nimport sys\nimport sqlparse\nimport hashlib\nimport json\nimport shutil\nimport re\nfrom pathlib import Path\n\ndef is_read_query(query):\n    \"\"\"Check if query is a read query (SELECT)\"\"\"\n    try:\n        parsed = sqlparse.parse(query)\n        if not parsed:\n            return False\n        first_token = str(parsed[0].get_real_name()).upper()\n        return first_token == 'SELECT'\n    except:\n        return False\n\ndef optimize_query(query):\n    \"\"\"Optimize query: uppercase keywords, spaces around operators, single line\"\"\"\n    try:\n        # Format with sqlparse\n        formatted = sqlparse.format(query, \n                                  keyword_case='upper', \n                                  indent_columns=True,\n                                  indent_tabs=False,\n                                  wrap_after=False)\n        \n        # Replace newlines with spaces and clean up whitespace\n        result = re.sub(r'\\s+', ' ', formatted).strip()\n        r"]
[86.864482, "i", "eturn result\n    except Exception as e:\n        print(f\"Error optimizing query: {e}\")\n        return query\n\ndef get_query_hash(query):\n    \"\"\"Get MD5 hash of the original query string\"\"\"\n    return hashlib.md5(query.strip().encode('utf-8')).hexdigest()\n\ndef process_batch():\n    \"\"\"Main processing function\"\"\"\n    # Get batch ID from environment\n    batch_id = os.getenv('DB_BATCH_ID')\n    if not batch_id:\n        print(\"Error: DB_BATCH_ID environment variable not set\")\n        sys.exit(1)\n    \n    # Define file paths\n    input_file = Path(f\"raw_batch_{batch_id}.sql\")\n    backup_file = Path(f\"raw_batch_{batch_id}_backup.sql\") \n    read_output = Path(f\"batch_{batch_id}_optimized_read.sql\")\n    write_output = Path(f\"batch_{batch_id}_optimized_write.sql\")\n    manifest_file = Path(f\"batch_{batch_id}_manifest.json\")\n    log_file = Path(f\"batch_{batch_id}_pipeline.log\")\n    \n    # Create backup\n    if input_file.exists():\n        shutil.copy(input_file, backup_file)\n    else:\n        print(f\"Error: Input file {input_f"]
[86.86454, "i", "ile} does not exist\")\n        sys.exit(1)\n    \n    # Initialize output files and counters\n    read_queries = []\n    write_queries = []\n    total_queries = 0\n    \n    # Read and process queries\n    with open(input_file, 'r') as f:\n        for line in f:\n            # Consider only non-empty lines\n            if not line.strip():\n                continue\n            \n            original_query = line.strip()\n            total_queries += 1\n            \n            # Get hash and optimize\n            query_hash = get_query_hash(original_query)\n            optimized_query = optimize_query(original_query)\n            \n            # Classify query\n            if is_read_query(original_query):\n                read_queries.append(f\"{optimized_query} -- id={query_hash};\\n\")\n            else:\n                write_queries.append(f\"{optimized_query} -- id={query_hash};\\n\")\n    \n    # Write output files\n    with open(read_output, 'w') as f:\n        f.writelines(read_queries)\n    \n    with open(write_output, 'w') as f:\n   "]
[86.864597, "o", "cat > process_batch.py << 'EOF'\r\n\u001b[?2004l\rile} does not exist\")\r\n        sys.exit(1)\r\n    \r\n    # Initialize output files and counters\r\n    read_queries = []\r\n    write_que"]
[86.864645, "i", "     f.writelines(write_queries)\n    \n    # Create manifest\n    manifest = {\n        \"batch_id\": batch_id,\n        \"read_count\": len(read_queries),\n        \"write_count\": len(write_queries)\n    }\n    with open(manifest_file, 'w') as f:\n        json.dump(manifest, f, indent=2)\n    \n    # Create log file\n    log_content = f\"\"\"PIPELINE START\nBatch ID: {batch_id}\nInput: {input_file}\nProcessed: {total_queries}\nPIPELINE END\n\"\"\"\n    with open(log_file, 'w') as f:\n        f.write(log_content)\n    \n    print(f\"Processing complete for batch {batch_id}\")\n    print(f\"- Read queries: {len(read_queries)}\")\n    print(f\"- Write queries: {len(write_queries)}\")\n\nif __name__ == \"__main__\":\n    process_batch()\nEOF"]
[86.864691, "o", "ries = []\r\n    total_queries = 0\r\n    \r\n    # Read and process queries\r\n    with open(input_file, 'r') as f:\r\n        for line in f:\r\n            # Consider only non-empty lines\r\n            if not line.strip():\r\n                continue\r\n            \r\n            original_query = line.strip()\r\n            total_queries += 1\r\n          "]
[86.864708, "o", "  \r\n            # Get hash and optimize\r\n            query_hash = get_query_hash(original_query)\r\n            optimized_query = optimize_query(original_query)\r\n            \r\n            # Classify query\r\n            if is_read_query(ori"]
[86.864785, "o", "ginal_query):\r\n                read_queries.append(f\"{optimized_query} -- id={query_hash};\\n\")\r\n            else:\r\n                write_queries.append(f\"{optimized_query} -- id={query_hash};\\n\")\r\n    \r\n    # Write output files\r\n    with open(read_output, 'w') as f:\r\n        f.writelines(read_queries)\r\n    \r\n    with open(write_output, 'w') as"]
[86.864826, "o", " f:\r\n   "]
[86.86487, "o", "     f.writelines(write_queries)\r\n    \r\n    # Create manifest\r\n    manifest = {\r\n        \"batch_id\": batch_id,\r\n        \"read_count\": len(read_queries),\r\n        \"write_count\": len(write_queries)\r\n    }\r\n    with open(manifest_file, 'w') as f:\r\n  "]
[86.864913, "o", "      json.dump(manifest, f, indent=2)\r\n    \r\n    # Create log file\r\n    log_content = f\"\"\"PIPELINE START\r\nBatch ID: {batch_id}\r\nInput: {input_file}\r\nProcesse"]
[86.864959, "o", "d: {total_queries}\r\nPIPELINE END\r\n\"\"\"\r\n    with open(log_file, 'w') as f:\r\n        f.wri"]
[86.865003, "o", "te(log_content)\r\n    \r\n    print(f\"Processing complete for batch {batch_id}\")\r\n    print(f\"- Read queries: {len(read_queries)}\")\r\n    print(f\"- Write queries: {len(write_queries)}\")\r\n\r\nif __name__ == \"__main__\":\r\n    process_batch()\r\nEOF\u001b[?2004h> "]
[86.865108, "o", "#!/usr/bin/env python3\r\n\u001b[?2004l\r"]
[86.865151, "o", "\u001b[?2004h> \r\n\u001b[?2004l\r"]
[86.865192, "o", "\u001b[?2004h> "]
[86.865237, "o", "import os\r\n\u001b[?2004l\r"]
[86.86527, "o", "\u001b[?2004h"]
[86.865282, "o", "> "]
[86.865336, "o", "import sys\r\n\u001b[?2004l\r"]
[86.865378, "o", "\u001b[?2004h> "]
[86.865447, "o", "import sqlparse\r\n\u001b[?2004l\r"]
[86.86549, "o", "\u001b[?2004h> "]
[86.865562, "o", "import hashlib\r\n\u001b[?2004l\r"]
[86.865612, "o", "\u001b[?2004h> "]
[86.865672, "o", "import json\r\n\u001b[?2004l\r"]
[86.865716, "o", "\u001b[?2004h> "]
[86.865782, "o", "import shutil\r\n\u001b[?2004l\r"]
[86.865822, "o", "\u001b[?2004h"]
[86.865835, "o", "> "]
[86.865888, "o", "import re\r\n\u001b[?2004l\r\u001b[?2004h"]
[86.86593, "o", "> "]
[86.866018, "o", "from pathlib import Path\r\n"]
[86.86603, "o", "\u001b[?2004l\r"]
[86.866082, "o", "\u001b[?2004h> \r\n\u001b[?2004l\r\u001b[?2004h"]
[86.866124, "o", "> "]
[86.866219, "o", "def is_read_query(query):\r\n\u001b[?2004l\r"]
[86.866258, "o", "\u001b[?2004h"]
[86.866299, "o", "> "]
[86.866487, "o", "    \"\"\"Check if query is a read query (SELECT)\"\"\"\r\n\u001b[?2004l\r"]
[86.866525, "o", "\u001b[?2004h> "]
[86.86661, "o", "    try:\r\n\u001b[?2004l\r"]
[86.866643, "o", "\u001b[?2004h"]
[86.866683, "o", "> "]
[86.866824, "o", "        parsed = sqlparse.parse(query)\r\n\u001b[?2004l\r"]
[86.866869, "o", "\u001b[?2004h> "]
[86.866971, "o", "        if not parsed:\r\n\u001b[?2004l\r"]
[86.867017, "o", "\u001b[?2004h> "]
[86.867123, "o", "            return False\r\n\u001b[?2004l\r"]
[86.867163, "o", "\u001b[?2004h> "]
[86.86743, "o", "        first_token = str(parsed[0].get_real_name()).upper()\r\n\u001b[?2004l\r"]
[86.867474, "o", "\u001b[?2004h> "]
[86.867668, "o", "        return first_token == 'SELECT'\r\n\u001b[?2004l\r"]
[86.867708, "o", "\u001b[?2004h> "]
[86.867778, "o", "    except:\r\n\u001b[?2004l\r"]
[86.867819, "o", "\u001b[?2004h> "]
[86.867914, "o", "        return False\r\n\u001b[?2004l\r"]
[86.867961, "o", "\u001b[?2004h> \r\n\u001b[?2004l\r"]
[86.868005, "o", "\u001b[?2004h> "]
[86.868117, "o", "def optimize_query(query):\r\n\u001b[?2004l\r"]
[86.868161, "o", "\u001b[?2004h> "]
[86.868514, "o", "    \"\"\"Optimize query: uppercase keywords, spaces around operators, single line\"\"\"\r\n\u001b[?2004l\r"]
[86.868564, "o", "\u001b[?2004h> "]
[86.868612, "o", "    try:\r\n\u001b[?2004l\r"]
[86.868655, "o", "\u001b[?2004h"]
[86.868703, "o", "> "]
[86.868816, "o", "        # Format with sqlparse\r\n\u001b[?2004l\r"]
[86.868848, "o", "\u001b[?2004h"]
[86.868894, "o", "> "]
[86.869053, "o", "        formatted = sqlparse.format(query, \r\n\u001b[?2004l\r"]
[86.869098, "o", "\u001b[?2004h> "]
[86.869342, "o", "                                  keyword_case='upper', \r\n\u001b[?2004l\r"]
[86.869383, "o", "\u001b[?2004h> "]
[86.869638, "o", "                                  indent_columns=True,\r\n\u001b[?2004l\r"]
[86.869676, "o", "\u001b[?2004h"]
[86.869689, "o", "> "]
[86.869911, "o", "                                  indent_tabs=False,\r\n\u001b[?2004l\r"]
[86.869951, "o", "\u001b[?2004h> "]
[86.87018, "o", "                                  wrap_after=False)\r\n\u001b[?2004l\r"]
[86.870226, "o", "\u001b[?2004h> "]
[86.870261, "o", "        \r\n\u001b[?2004l\r"]
[86.870303, "o", "\u001b[?2004h> "]
[86.870588, "o", "        # Replace newlines with spaces and clean up whitespace\r\n\u001b[?2004l\r"]
[86.87063, "o", "\u001b[?2004h> "]
[86.870881, "o", "        result = re.sub(r'\\s+', ' ', formatted).strip()\r\n\u001b[?2004l\r"]
[86.870919, "o", "\u001b[?2004h> "]
[86.871021, "o", "        return result\r\n"]
[86.871032, "o", "\u001b[?2004l\r"]
[86.871048, "o", "\u001b[?2004h"]
[86.871059, "o", "> "]
[86.871179, "o", "    except Exception as e:\r\n\u001b[?2004l\r"]
[86.871218, "o", "\u001b[?2004h> "]
[86.871425, "o", "        print(f\"Error optimizing query: {e}\")\r\n\u001b[?2004l\r"]
[86.871468, "o", "\u001b[?2004h> "]
[86.87157, "o", "        return query"]
[86.871583, "o", "\r\n\u001b[?2004l\r"]
[86.871629, "o", "\u001b[?2004h> \r\n\u001b[?2004l\r"]
[86.87168, "o", "\u001b[?2004h> "]
[86.871799, "o", "def get_query_hash(query):\r\n\u001b[?2004l\r"]
[86.871825, "o", "\u001b[?2004h"]
[86.871853, "o", "> "]
[86.872066, "o", "    \"\"\"Get MD5 hash of the original query string\"\"\"\r\n\u001b[?2004l\r"]
[86.872091, "o", "\u001b[?2004h"]
[86.872118, "o", "> "]
[86.872397, "o", "    return hashlib.md5(query.strip().encode('utf-8')).hexdigest()\r\n\u001b[?2004l\r"]
[86.872427, "o", "\u001b[?2004h"]
[86.872455, "o", "> \r\n\u001b[?2004l\r"]
[86.872482, "o", "\u001b[?2004h> "]
[86.872614, "o", "def process_batch():\r\n\u001b[?2004l\r"]
[86.872636, "o", "\u001b[?2004h"]
[86.872664, "o", "> "]
[86.872808, "o", "    \"\"\"Main processing function\"\"\"\r\n\u001b[?2004l\r"]
[86.872838, "o", "\u001b[?2004h"]
[86.872864, "o", "> "]
[86.873018, "o", "    # Get batch ID from environment\r\n\u001b[?2004l\r"]
[86.873049, "o", "\u001b[?2004h"]
[86.873073, "o", "> "]
[86.873245, "o", "    batch_id = os.getenv('DB_BATCH_ID')\r\n\u001b[?2004l\r"]
[86.873275, "o", "\u001b[?2004h"]
[86.873303, "o", "> "]
[86.87339, "o", "    if not batch_id:\r\n\u001b[?2004l\r"]
[86.87342, "o", "\u001b[?2004h"]
[86.873447, "o", "> "]
[86.873765, "o", "        print(\"Error: DB_BATCH_ID environment variable not set\")\r\n\u001b[?2004l\r"]
[86.873796, "o", "\u001b[?2004h"]
[86.873822, "o", "> "]
[86.873907, "o", "        sys.exit(1)\r\n\u001b[?2004l\r"]
[86.873937, "o", "\u001b[?2004h"]
[86.873962, "o", "> "]
[86.873992, "o", "    \r\n\u001b[?2004l\r"]
[86.874019, "o", "\u001b[?2004h> "]
[86.874124, "o", "    # Define file paths\r\n"]
[86.874149, "o", "\u001b[?2004l\r"]
[86.874177, "o", "\u001b[?2004h> "]
[86.8744, "o", "    input_file = Path(f\"raw_batch_{batch_id}.sql\")\r\n\u001b[?2004l\r"]
[86.874431, "o", "\u001b[?2004h"]
[86.874459, "o", "> "]
[86.87476, "o", "    backup_file = Path(f\"raw_batch_{batch_id}_backup.sql\") \r\n\u001b[?2004l\r"]
[86.874791, "o", "\u001b[?2004h"]
[86.874816, "o", "> "]
[86.875087, "o", "    read_output = Path(f\"batch_{batch_id}_optimized_read.sql\")\r\n\u001b[?2004l\r"]
[86.875118, "o", "\u001b[?2004h"]
[86.875143, "o", "> "]
[86.875423, "o", "    write_output = Path(f\"batch_{batch_id}_optimized_write.sql\")\r\n\u001b[?2004l\r"]
[86.875453, "o", "\u001b[?2004h"]
[86.87548, "o", "> "]
[86.875781, "o", "    manifest_file = Path(f\"batch_{batch_id}_manifest.json\")\r\n\u001b[?2004l\r"]
[86.875813, "o", "\u001b[?2004h"]
[86.87584, "o", "> "]
[86.876071, "o", "    log_file = Path(f\"batch_{batch_id}_pipeline.log\")\r\n\u001b[?2004l\r"]
[86.876102, "o", "\u001b[?2004h"]
[86.876128, "o", "> "]
[86.876153, "o", "    \r\n\u001b[?2004l\r"]
[86.876177, "o", "\u001b[?2004h"]
[86.876202, "o", "> "]
[86.876275, "o", "    # Create backup\r\n"]
[86.876301, "o", "\u001b[?2004l\r"]
[86.876326, "o", "\u001b[?2004h> "]
[86.876447, "o", "    if input_file.exists():\r\n"]
[86.876472, "o", "\u001b[?2004l\r"]
[86.876498, "o", "\u001b[?2004h> "]
[86.876707, "o", "        shutil.copy(input_file, backup_file)\r\n\u001b[?2004l\r"]
[86.876737, "o", "\u001b[?2004h"]
[86.876765, "o", "> "]
[86.876803, "o", "    else:\r\n"]
[86.876827, "o", "\u001b[?2004l\r\u001b[?2004h"]
[86.876851, "o", "> "]
[86.877134, "o", "        print(f\"Error: Input file {input_file} does not exist\")\r\n\u001b[?2004l\r"]
[86.877172, "o", "\u001b[?2004h"]
[86.877197, "o", "> "]
[86.877284, "o", "        sys.exit(1)\r\n\u001b[?2004l\r"]
[86.877314, "o", "\u001b[?2004h"]
[86.877339, "o", "> "]
[86.877365, "o", "    \r\n\u001b[?2004l\r"]
[86.877386, "o", "\u001b[?2004h"]
[86.877412, "o", "> "]
[86.877635, "o", "    # Initialize output files and counters\r\n\u001b[?2004l\r"]
[86.877666, "o", "\u001b[?2004h> "]
[86.87777, "o", "    read_queries = []\r\n"]
[86.877795, "o", "\u001b[?2004l\r\u001b[?2004h"]
[86.877817, "o", "> "]
[86.877923, "o", "    write_queries = []\r\n\u001b[?2004l\r"]
[86.877953, "o", "\u001b[?2004h"]
[86.87798, "o", "> "]
[86.878085, "o", "    total_queries = 0\r\n\u001b[?2004l\r"]
[86.878124, "o", "\u001b[?2004h> "]
[86.878154, "o", "    \r\n\u001b[?2004l\r"]
[86.878183, "o", "\u001b[?2004h> "]
[86.87832, "o", "    # Read and process queries\r\n\u001b[?2004l\r"]
[86.878348, "o", "\u001b[?2004h"]
[86.878375, "o", "> "]
[86.878525, "o", "    with open(input_file, 'r') as f:\r\n\u001b[?2004l\r"]
[86.878559, "o", "\u001b[?2004h"]
[86.878588, "o", "> "]
[86.878694, "o", "        for line in f:\r\n\u001b[?2004l\r"]
[86.878726, "o", "\u001b[?2004h"]
[86.878754, "o", "> "]
[86.87894, "o", "            # Consider only non-empty lines\r\n\u001b[?2004l\r"]
[86.87897, "o", "\u001b[?2004h"]
[86.878999, "o", "> "]
[86.879137, "o", "            if not line.strip():\r\n\u001b[?2004l\r"]
[86.879167, "o", "\u001b[?2004h"]
[86.879195, "o", "> "]
[86.879302, "o", "                continue\r\n\u001b[?2004l\r"]
[86.879332, "o", "\u001b[?2004h"]
[86.879358, "o", "> "]
[86.879403, "o", "            \r\n\u001b[?2004l\r"]
[86.879428, "o", "\u001b[?2004h"]
[86.879455, "o", "> "]
[86.879648, "o", "            original_query = line.strip()\r\n\u001b[?2004l\r"]
[86.879682, "o", "\u001b[?2004h"]
[86.879709, "o", "> "]
[86.879834, "o", "            total_queries += 1\r\n\u001b[?2004l\r"]
[86.879859, "o", "\u001b[?2004h"]
[86.879886, "o", "> "]
[86.879931, "o", "            \r\n\u001b[?2004l\r"]
[86.879957, "o", "\u001b[?2004h"]
[86.879983, "o", "> "]
[86.880129, "o", "            # Get hash and optimize\r\n\u001b[?2004l\r"]
[86.880154, "o", "\u001b[?2004h"]
[86.880179, "o", "> "]
[86.880414, "o", "            query_hash = get_query_hash(original_query)\r\n\u001b[?2004l\r"]
[86.88044, "o", "\u001b[?2004h"]
[86.880466, "o", "> "]
[86.880745, "o", "            optimized_query = optimize_query(original_query)\r\n\u001b[?2004l\r"]
[86.880777, "o", "\u001b[?2004h"]
[86.880805, "o", "> "]
[86.880857, "o", "            \r\n\u001b[?2004l\r"]
[86.880885, "o", "\u001b[?2004h"]
[86.880905, "o", "> "]
[86.881048, "o", "            # Classify query\r\n\u001b[?2004l\r"]
[86.881073, "o", "\u001b[?2004h"]
[86.881099, "o", "> "]
[86.881307, "o", "            if is_read_query(original_query):\r\n"]
[86.88133, "o", "\u001b[?2004l\r"]
[86.881352, "o", "\u001b[?2004h> "]
[86.881764, "o", "                read_queries.append(f\"{optimized_query} -- id={query_hash};\\n\")\r\n\u001b[?2004l\r"]
[86.881844, "o", "\u001b[?2004h> "]
[86.881902, "o", "            else:\r\n\u001b[?2004l\r"]
[86.881939, "o", "\u001b[?2004h"]
[86.881956, "o", "> "]
[86.882325, "o", "                write_queries.append(f\"{optimized_query} -- id={query_hash};\\n\")\r\n\u001b[?2004l\r"]
[86.88235, "o", "\u001b[?2004h"]
[86.882366, "o", "> "]
[86.882398, "o", "    \r\n"]
[86.882415, "o", "\u001b[?2004l\r"]
[86.882431, "o", "\u001b[?2004h"]
[86.882447, "o", "> "]
[86.882584, "o", "    # Write output files\r\n\u001b[?2004l\r"]
[86.882616, "o", "\u001b[?2004h"]
[86.882633, "o", "> "]
[86.882812, "o", "    with open(read_output, 'w') as f:\r\n\u001b[?2004l\r"]
[86.882842, "o", "\u001b[?2004h"]
[86.882858, "o", "> "]
[86.883026, "o", "        f.writelines(read_queries)\r\n\u001b[?2004l\r"]
[86.883055, "o", "\u001b[?2004h"]
[86.883071, "o", "> "]
[86.883103, "o", "    \r\n"]
[86.883121, "o", "\u001b[?2004l\r"]
[86.883138, "o", "\u001b[?2004h"]
[86.883154, "o", "> "]
[86.883343, "o", "    with open(write_output, 'w') as f:\r\n\u001b[?2004l\r"]
[86.883409, "o", "\u001b[?2004h> "]
[86.883578, "o", "        f.writelines(write_queries)\r\n\u001b[?2004l\r"]
[86.883625, "o", "\u001b[?2004h> "]
[86.883682, "o", "    \r\n\u001b[?2004l\r"]
[86.883714, "o", "\u001b[?2004h> "]
[86.883827, "o", "    # Create manifest\r\n\u001b[?2004l\r"]
[86.88386, "o", "\u001b[?2004h"]
[86.883888, "o", "> "]
[86.88397, "o", "    manifest = {\r\n\u001b[?2004l\r"]
[86.884009, "o", "\u001b[?2004h> "]
[86.884151, "o", "        \"batch_id\": batch_id,\r\n"]
[86.884171, "o", "\u001b[?2004l\r"]
[86.884192, "o", "\u001b[?2004h> "]
[86.884385, "o", "        \"read_count\": len(read_queries),\r\n\u001b[?2004l\r"]
[86.884416, "o", "\u001b[?2004h"]
[86.884434, "o", "> "]
[86.884639, "o", "        \"write_count\": len(write_queries)\r\n\u001b[?2004l\r"]
[86.884668, "o", "\u001b[?2004h"]
[86.884686, "o", "> "]
[86.884717, "o", "    }\r\n"]
[86.884735, "o", "\u001b[?2004l\r"]
[86.884752, "o", "\u001b[?2004h"]
[86.884771, "o", "> "]
[86.884964, "o", "    with open(manifest_file, 'w') as f:\r\n"]
[86.884995, "o", "\u001b[?2004l\r\u001b[?2004h"]
[86.88502, "o", "> "]
[86.885231, "o", "        json.dump(manifest, f, indent=2)\r\n\u001b[?2004l\r"]
[86.885283, "o", "\u001b[?2004h> "]
[86.8853, "o", "    \r\n\u001b[?2004l\r"]
[86.885348, "o", "\u001b[?2004h"]
[86.885374, "o", "> "]
[86.885461, "o", "    # Create log file\r\n\u001b[?2004l\r"]
[86.885495, "o", "\u001b[?2004h"]
[86.886566, "o", ">     log_content = f\"\"\"PIPELINE START\r\n\u001b[?2004l\r\u001b[?2004h> Batch ID: {batch_id}\r\n\u001b[?2004l\r\u001b[?2004h> Input: {input_file}\r\n\u001b[?2004l\r\u001b[?2004h> Processed: {total_queries}\r\n\u001b[?2004l\r\u001b[?2004h> PIPELINE END\r\n\u001b[?2004l\r\u001b[?2004h> \"\"\"\r\n\u001b[?2004l\r\u001b[?2004h>     with open(log_file, 'w') as f:\r\n\u001b[?2004l\r"]
[86.88675, "o", "\u001b[?2004h>         f.write(log_content)\r\n\u001b[?2004l\r"]
[86.886808, "o", "\u001b[?2004h>     \r\n"]
[86.886866, "o", "\u001b[?2004l\r\u001b[?2004h> "]
[86.887108, "o", "    print(f\"Processing complete for batch {batch_id}\")\r\n\u001b[?2004l\r"]
[86.887154, "o", "\u001b[?2004h> "]
[86.887423, "o", "    print(f\"- Read queries: {len(read_queries)}\")\r\n\u001b[?2004l\r"]
[86.887455, "o", "\u001b[?2004h> "]
[86.887718, "o", "    print(f\"- Write queries: {len(write_queries)}\")\r\n\u001b[?2004l\r"]
[86.887752, "o", "\u001b[?2004h"]
[86.887783, "o", "> \r\n\u001b[?2004l\r\u001b[?2004h> "]
[86.887919, "o", "if __name__ == \"__main__\":\r\n\u001b[?2004l\r"]
[86.887949, "o", "\u001b[?2004h> "]
[86.888054, "o", "    process_batch()\r\n\u001b[?2004l\r"]
[86.888081, "o", "\u001b[?2004h> "]
[86.888111, "o", "EOF"]
[102.708122, "i", "cat > raw_batch_42.sql << 'EOF'\nselect * from employees;\nUPDATE departments SET location_id = 1700 WHERE department_id = 10;\nSELECT employee_id, first_name, last_name FROM employees WHERE salary > 50000;\nINSERT INTO departments (department_id, department_name) VALUES (280, 'Game Developers');\nDELETE FROM job_history WHERE end_date < '2000-01-01';\nselect * from t;\nEOF"]
[102.708285, "o", "cat > raw_batch_42.sql << 'EOF'\r\n\u001b[?2004l\r"]
[102.708343, "o", "\u001b[?2004h> "]
[102.708393, "o", "select * from employees;\r\n\u001b[?2004l\r\u001b[?2004h> "]
[102.708601, "o", "UPDATE departments SET location_id = 1700 WHERE department_id = 10;\r\n\u001b[?2004l\r"]
[102.708617, "o", "\u001b[?2004h> "]
[102.708847, "o", "SELECT employee_id, first_name, last_name FROM employees WHERE salary > 50000;\r\n\u001b[?2004l\r\u001b[?2004h"]
[102.708863, "o", "> "]
[102.709093, "o", "INSERT INTO departments (department_id, department_name) VALUES (280, 'Game Developers');\r\n\u001b[?2004l\r"]
[102.70911, "o", "\u001b[?2004h> "]
[102.709275, "o", "DELETE FROM job_history WHERE end_date < '2000-01-01';\r\n\u001b[?2004l\r\u001b[?2004h"]
[102.709322, "o", "> "]
[102.70937, "o", "select * from t;\r\n\u001b[?2004l\r\u001b[?2004h> EOF"]
[103.160964, "i", "export DB_BATCH_ID=42\n"]
[103.161165, "o", "export DB_BATCH_ID=42\r\n"]
[103.161194, "o", "\u001b[?2004l\r"]
[103.161246, "o", "\u001b[?2004h"]
[103.161273, "o", "> "]
[103.28854, "i", "python process_batch.py\n"]
[103.288774, "o", "python process_batch.py\r\n\u001b[?2004l\r"]
[103.288846, "o", "\u001b[?2004h> "]
[116.532784, "i", "ls -la\n"]
[116.532924, "o", "ls -la\r\n\u001b[?2004l\r"]
[116.532944, "o", "\u001b[?2004h> "]
[116.649947, "i", "echo \"select * from employees;\\nUPDATE departments SET location_id = 1700 WHERE department_id = 10;\\nSELECT employee_id, first_name, last_name FROM employees WHERE salary > 50000;\\nINSERT INTO departments (department_id, department_name) VALUES (280, 'Game Developers');\\nDELETE FROM job_history WHERE end_date < '2000-01-01';\\nselect * from t;\" > raw_batch_42.sql\n"]
[116.652774, "o", "echo \"select * from employees;\\nUPDATE departments SET location_id = 1700 WHERE department_id = 10;\\nSELECT employee_id, first_name, last_name FROM employees WHERE salary > 50000;\\nINSERT INTO departments (department_id, department_name) VALUES (280, 'Game Developers');\\nDELETE FROM job_history WHERE end_date < '2000-01-01';\\nselect * from t;\" > raw_batch_42.sql\r\n\u001b[?2004l\r"]
[116.652838, "o", "\u001b[?2004h> "]
[127.118498, "i", "\n"]
[127.118606, "o", "\r\n\u001b[?2004l\r"]
[127.118665, "o", "\u001b[?2004h"]
[127.118688, "o", "> "]
[127.40754, "i", "pwd\n"]
[127.407659, "o", "pwd\r\n\u001b[?2004l\r"]
[127.4077, "o", "\u001b[?2004h"]
[127.407725, "o", "> "]
[127.641457, "i", "ls -la\n"]
[127.641604, "o", "ls -la\r\n\u001b[?2004l\r\u001b[?2004h"]
[127.641621, "o", "> "]
[138.848724, "i", "clear\n"]
[138.848815, "o", "clear\r\n\u001b[?2004l\r"]
[138.848851, "o", "\u001b[?2004h> "]
[138.978302, "i", "echo \"test\"\n"]
[138.978417, "o", "echo \"test\"\r\n\u001b[?2004l\r\u001b[?2004h"]
[138.978448, "o", "> "]
[150.197784, "i", "export DB_BATCH_ID=42; python process_batch.py\n"]
[150.198074, "o", "export DB_BATCH_ID=42; python process_batch.py\r\n\u001b[?2004l\r"]
[150.198132, "o", "\u001b[?2004h"]
[150.198158, "o", "> "]
[164.736073, "i", "ls -la *.sql *.py *.json *.log 2>/dev/null || echo \"Files not found\"\n"]
[164.736673, "o", "ls -la *.sql *.py *.json *.log 2>/dev/null || echo \"Files not found\"\r\n\u001b[?2004l\r"]
[164.736736, "o", "\u001b[?2004h> "]
[181.287012, "i", "echo \"sqlparse==0.4.4\nsqlparse==0.4.4\"\n"]
[181.287216, "o", "echo \"sqlparse==0.4.4\r\n"]
[181.287263, "o", "\u001b[?2004l\r"]
[181.287292, "o", "\u001b[?2004h"]
[181.287318, "o", "> "]
[181.287423, "o", "sqlparse==0.4.4\"\r\n\u001b[?2004l\r"]
[181.287464, "o", "\u001b[?2004h"]
[181.28748, "o", "> "]
[181.423112, "i", "echo '{\\n  \\\"batch_id\\\": \\\"42\\\",\\n  \\\"read_count\\\": 3,\\n  \\\"write_count\\\": 3\\n}'\n"]
[181.423368, "o", "echo '{\\n  \\\"batch_id\\\": \\\"42\\\",\\n  \\\"read_count\\\": 3,\\n  \\\"write_count\\\": 3\\n}'\r\n\u001b[?2004l\r"]
[181.423401, "o", "\u001b[?2004h> "]
[181.650611, "i", "echo 'PIPELINE START\\nBatch ID: 42\\nInput: raw_batch_42.sql\\nProcessed: 6\\nPIPELINE END'\n"]
[181.65107, "o", "echo 'PIPELINE START\\nBatch ID: 42\\nInput: raw_batch_42.sql\\nProcessed: 6\\nPIPELINE END'\r\n\u001b[?2004l\r"]
[181.651117, "o", "\u001b[?2004h"]
[181.651151, "o", "> "]
